import streamlit as st
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import pearsonr, t
import itertools
import io

# ==========================================
# 1. æ ¸å¿ƒç»Ÿè®¡å·¥å…·
# ==========================================

def get_stars(p_value):
    """å°†På€¼è½¬æ¢ä¸ºæ˜Ÿå·"""
    if p_value < 0.001: return '***'
    if p_value < 0.01:  return '**'
    if p_value < 0.05:  return '*'
    return 'ns'

def pairwise_lsd_test_with_mse(stats_df, mse, df_resid, alpha=0.05):
    """Fisher's LSD æ£€éªŒ"""
    results = []
    group_names = stats_df.index.tolist()
    
    for g1, g2 in itertools.combinations(group_names, 2):
        m1, n1 = stats_df.loc[g1, 'mean'], stats_df.loc[g1, 'count']
        m2, n2 = stats_df.loc[g2, 'mean'], stats_df.loc[g2, 'count']
        
        diff = m1 - m2
        se = np.sqrt(mse * (1/n1 + 1/n2))
        
        if se <= 1e-10: 
            p_val = 1.0
        else:
            t_stat = abs(diff) / se
            p_val = 2 * (1 - t.cdf(t_stat, df_resid))
        
        reject = p_val < alpha
        results.append([g1, g2, diff, p_val, reject])
        
    return results

def solve_clique_cld(means, pairwise_data, use_uppercase=False):
    """æœ€å¤§å›¢ç®—æ³•ç”Ÿæˆå­—æ¯æ ‡è®°"""
    groups = [str(g).strip() for g in means.index.tolist()]
    n = len(groups)
    g_to_i = {g: i for i, g in enumerate(groups)}
    adj = np.ones((n, n), dtype=bool) 
    
    if pairwise_data:
        for row in pairwise_data:
            g1, g2, reject = str(row[0]).strip(), str(row[1]).strip(), row[4]
            if reject: 
                if g1 in g_to_i and g2 in g_to_i:
                    i, j = g_to_i[g1], g_to_i[g2]
                    adj[i, j] = False
                    adj[j, i] = False

    np.fill_diagonal(adj, False) # ç§»é™¤è‡ªç¯

    cliques = []
    def bron_kerbosch(R, P, X):
        if len(P) == 0 and len(X) == 0:
            cliques.append(R)
            return
        pivot = next(iter(P.union(X))) if P.union(X) else None
        neighbors_pivot = {idx for idx in range(n) if adj[pivot, idx]} if pivot is not None else set()
        for v in list(P - neighbors_pivot):
            neighbors_v = {idx for idx in range(n) if adj[v, idx]}
            bron_kerbosch(R.union({v}), P.intersection(neighbors_v), X.intersection(neighbors_v))
            P.remove(v)
            X.add(v)

    bron_kerbosch(set(), set(range(n)), set())
    
    clique_means = []
    for clq in cliques:
        avg_mean = np.mean([means.iloc[i] for i in clq])
        clique_means.append((avg_mean, clq))
    
    clique_means.sort(key=lambda x: x[0], reverse=True)
    
    if use_uppercase:
        letters_list = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    else:
        letters_list = "abcdefghijklmnopqrstuvwxyz"
        
    group_letters = {i: "" for i in range(n)}
    
    for idx, (avg, clq) in enumerate(clique_means):
        char = letters_list[idx] if idx < len(letters_list) else "?"
        for node_idx in clq:
            group_letters[node_idx] += char
            
    final_res = {}
    original_index = means.index.tolist()
    for i in range(n):
        l_str = "".join(sorted(group_letters[i]))
        final_res[str(original_index[i]).strip()] = l_str
        
    return final_res

# ==========================================
# 2. æ ¸å¿ƒæµç¨‹ï¼šå®šåˆ¶åŒ–åˆ—ç»“æ„ (Updated)
# ==========================================

def run_comprehensive_analysis(df, factors, targets, test_factor):
    results = {}
    
    # æ•°æ®æ¸…æ´—
    work_df = df.copy()
    for f in factors:
        work_df[f] = work_df[f].astype(str).str.strip()
        
    group_factors = [f for f in factors if f != test_factor]
    
    anova_rows = []
    main_effects_rows = []
    sliced_comparison_rows = []
    
    for target in targets:
        try:
            # --- A. ANOVA ---
            formula = f"{target} ~ {' * '.join(factors)}"
            model = ols(formula, data=work_df).fit()
            
            aov_table = sm.stats.anova_lm(model, typ=2)
            global_mse = model.mse_resid
            global_df_resid = model.df_resid
            
            for source, row in aov_table.iterrows():
                if source == 'Residual': continue
                f_str = f"{row['F']:.2f}{get_stars(row['PR(>F)'])}"
                anova_rows.append({
                    'Trait': target,
                    'Source': source,
                    'F_Sig': f_str
                })
            
            # --- B. ä¸»æ•ˆåº” (å¤§å†™å­—æ¯, æ—  SD) ---
            for factor in factors:
                stats = work_df.groupby(factor)[target].agg(['mean', 'std', 'count']).fillna(0)
                
                if len(stats) < 2:
                    letters = {str(k).strip(): 'A' for k in stats.index}
                else:
                    pairwise_res = pairwise_lsd_test_with_mse(stats, global_mse, global_df_resid, alpha=0.05)
                    letters = solve_clique_cld(stats['mean'], pairwise_res, use_uppercase=True)
                
                for lvl in stats.index:
                    mean_val = stats.loc[lvl, 'mean']
                    sd_val = stats.loc[lvl, 'std']
                    lvl_str = str(lvl).strip()
                    let = letters.get(lvl_str, 'A')
                    
                    # ç»„åˆ: Mean + Letter (å¤§å†™)
                    mean_let = f"{mean_val:.2f} {let}"
                    
                    main_effects_rows.append({
                        'Factor': factor,
                        'Level': lvl_str,
                        'Trait': target,
                        'Mean_Letter': mean_let, 
                        # SD è¿™é‡Œè®¡ç®—äº†ä½†ä¸æ”¾å…¥ Pivot
                        'SD': sd_val 
                    })

            # --- C. åˆ‡ç‰‡æ¯”è¾ƒ (Mean, Letter, SD) ---
            if not group_factors:
                iter_groups = [( "All", work_df )] 
            else:
                iter_groups = work_df.groupby(group_factors)

            for group_keys, sub_df in iter_groups:
                if not isinstance(group_keys, tuple): group_keys = (group_keys,)
                
                current_info = {'Trait': target}
                if group_factors:
                    for k, val in zip(group_factors, group_keys):
                        current_info[k] = str(val)
                
                stats = sub_df.groupby(test_factor)[target].agg(['mean', 'std', 'count']).fillna(0)
                
                if len(stats) < 2:
                    letters = {str(k).strip(): 'a' for k in stats.index}
                else:
                    pairwise_res = pairwise_lsd_test_with_mse(stats, global_mse, global_df_resid, alpha=0.05)
                    letters = solve_clique_cld(stats['mean'], pairwise_res, use_uppercase=False)
                
                for lvl in stats.index:
                    mean_val = stats.loc[lvl, 'mean']
                    sd_val = stats.loc[lvl, 'std']
                    lvl_str = str(lvl).strip()
                    let = letters.get(lvl_str, 'a')
                    
                    row = current_info.copy()
                    row[test_factor] = lvl_str
                    
                    # åŸºç¡€æ•°æ®
                    row['Mean'] = mean_val
                    row['SD'] = sd_val
                    row['Letter'] = let
                    
                    # ç»„åˆæ•°æ®
                    row['Mean_Letter'] = f"{mean_val:.2f} {let}"
                    
                    sliced_comparison_rows.append(row)
                    
        except Exception as e:
            pass

    # --- D. ç”Ÿæˆè¡¨æ ¼ (Pivot) ---
    
    # 1. ANOVA è¡¨
    if anova_rows:
        anova_df = pd.DataFrame(anova_rows)
        results['anova_table'] = anova_df.pivot_table(
            index='Source', columns='Trait', values='F_Sig', aggfunc='first'
        )
    else:
        results['anova_table'] = pd.DataFrame()

    # 2. ä¸»æ•ˆåº”è¡¨ (Mean_Letter ONLY)
    if main_effects_rows:
        me_df = pd.DataFrame(main_effects_rows)
        # ä»… Pivot Mean_Letterï¼Œç§»é™¤ SD
        me_pivot = me_df.pivot_table(
            index=['Factor', 'Level'], 
            columns='Trait', 
            values=['Mean_Letter'], 
            aggfunc='first'
        )
        # è°ƒæ•´åˆ—é¡ºåº
        results['main_effects_table'] = me_pivot.swaplevel(0, 1, axis=1).sort_index(axis=1)
    else:
        results['main_effects_table'] = pd.DataFrame()

    # 3. åˆ‡ç‰‡æ¯”è¾ƒ (ä¸¤ç§æ ¼å¼)
    if sliced_comparison_rows:
        sc_df = pd.DataFrame(sliced_comparison_rows)
        pivot_index = group_factors + [test_factor]
        
        # æ ¼å¼ä¸€ï¼šMean, Letter, SD ä¸‰ä¸ªåˆ†å¼€ (æŒ‡å®šé¡ºåº)
        sc_pivot_sep = sc_df.pivot_table(
            index=pivot_index, 
            columns='Trait', 
            values=['Mean', 'Letter', 'SD'], 
            aggfunc='first'
        )
        # äº¤æ¢å±‚çº§: (Trait, Type)
        sc_pivot_sep = sc_pivot_sep.swaplevel(0, 1, axis=1)
        # å…ˆæŒ‰æŒ‡æ ‡æ’åº
        sc_pivot_sep = sc_pivot_sep.sort_index(axis=1, level=0)
        
        # ã€å…³é”®ä¿®æ”¹ã€‘å¼ºåˆ¶é‡æ’ Level 1 çš„é¡ºåº: Mean -> Letter -> SD
        # è·å–æ‰€æœ‰æ’å¥½åºçš„æŒ‡æ ‡
        sorted_traits = sc_pivot_sep.columns.get_level_values(0).unique()
        # æ„å»ºæ–°çš„åˆ—ç´¢å¼•é¡ºåº
        new_columns = []
        for t in sorted_traits:
            for val in ['Mean', 'Letter', 'SD']:
                new_columns.append((t, val))
        
        # åº”ç”¨é‡æ’
        results['sliced_table_sep'] = sc_pivot_sep.reindex(columns=new_columns)
        
        # æ ¼å¼äºŒï¼šä»… Mean + Letter ç»„åˆ
        sc_pivot_comb = sc_df.pivot_table(
            index=pivot_index, 
            columns='Trait', 
            values=['Mean_Letter'], 
            aggfunc='first'
        )
        results['sliced_table_comb'] = sc_pivot_comb.swaplevel(0, 1, axis=1).sort_index(axis=1)
    else:
        results['sliced_table_sep'] = pd.DataFrame()
        results['sliced_table_comb'] = pd.DataFrame()
        
    # 4. ç›¸å…³æ€§
    if len(targets) > 1:
        corr_matrix = pd.DataFrame(index=targets, columns=targets)
        for t1 in targets:
            for t2 in targets:
                if t1 == t2:
                    corr_matrix.loc[t1, t2] = "-"
                else:
                    valid = df[[t1, t2]].dropna()
                    if len(valid) > 2:
                        r, p = pearsonr(valid[t1], valid[t2])
                        corr_matrix.loc[t1, t2] = f"{r:.2f}{get_stars(p)}"
                    else:
                        corr_matrix.loc[t1, t2] = "NaN"
        results['correlation'] = corr_matrix
    else:
        results['correlation'] = pd.DataFrame()

    return results

# ==========================================
# 3. Streamlit ç•Œé¢
# ==========================================

st.set_page_config(page_title="è®ºæ–‡æ•°æ®åŠ©æ‰‹", layout="wide", page_icon="ğŸ“Š")
st.title("ğŸ“Š ç®€å•çš„æ•°æ®åˆ†æ")
# ==================== æ–°å¢éƒ¨åˆ†å¼€å§‹ ====================
with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜ & æ•°æ®æ ¼å¼ç¤ºä¾‹ (ç‚¹å‡»å±•å¼€)"):
    st.markdown("""
    **æ•°æ®å‡†å¤‡æŒ‡å—ï¼š**
    1. è¯·å‡†å¤‡ Excel (.xlsx) æˆ– CSV æ–‡ä»¶ã€‚
    2. **ç¬¬ä¸€è¡Œ**å¿…é¡»æ˜¯åˆ—åï¼ˆå¦‚ï¼šå“ç§ã€å¤„ç†ã€äº§é‡ã€æ ªé«˜ï¼‰ã€‚
    3. æ•°æ®åº”ä¸º**é•¿æ ¼å¼ (Long Format)**ï¼Œå³æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªé‡å¤æˆ–æ ·æœ¬ã€‚
    """)
    
    # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„ç¤ºä¾‹æ•°æ®
    demo_data = pd.DataFrame({
       'å“ç§': ['V1', 'V1', 'V1' ],
        'å¤„ç†': ['CK', 'CK', 'CK'],
        'é‡å¤': ['R1', 'R2', 'R3'],
        'äº§é‡(kg)': [500.2, 520.5, 480.1],
        'æ ªé«˜(cm)': [100.5, 105.2, 98.4]
    })
    
    # å±•ç¤ºè¡¨æ ¼
    st.table(demo_data)
    st.caption("æ³¨ï¼šå› å­åˆ—ï¼ˆå¦‚å“ç§ã€å¤„ç†ï¼‰å¯ä»¥æ˜¯æ–‡å­—æˆ–æ•°å­—ï¼›æŒ‡æ ‡åˆ—ï¼ˆå¦‚äº§é‡ï¼‰å¿…é¡»æ˜¯æ•°å­—ã€‚")
# ==================== æ–°å¢éƒ¨åˆ†ç»“æŸ ====================

st.info(...) # åŸæ¥çš„ info ä»£ç 

# ... (åé¢çš„ä¾§è¾¹æ ä»£ç ä¸å˜) ...
st.info("""
âœ… **ç»„å†…æ¯”è¾ƒ**ï¼š
   - **æ ¼å¼ A**ï¼šMean, Letter, SD ä¸¥æ ¼æŒ‰æ­¤é¡ºåºåˆ†åˆ— (æ–¹ä¾¿ä½œå›¾)
   - **æ ¼å¼ B**ï¼šMean+Letter ç»„åˆ (æ–¹ä¾¿åˆ¶è¡¨)
âœ… **ä¸»æ•ˆåº”**ï¼š
   - ä»…ä¿ç•™ **Mean + å¤§å†™Letter** (ç§»é™¤ SD åˆ—)
""")

with st.sidebar:
    st.header("1. æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader("ä¸Šä¼  Excel/CSV", type=['xlsx', 'csv'])
    
    st.header("2. å‚æ•°è®¾ç½®")
    factors = []
    targets = []
    test_factor = None
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            df.columns = df.columns.astype(str)
            all_cols = df.columns.tolist()
            
            st.markdown("---")
            factors = st.multiselect("å› å­ (X)", all_cols)
            
            if factors:
                default_idx = len(factors) - 1
                test_factor = st.selectbox("æ¯”è¾ƒå› å­ (ç”¨äºç»„å†…æ¯”è¾ƒ)", factors, index=default_idx)
            
            targets = st.multiselect("æŒ‡æ ‡ (Y)", all_cols)
            
            run_btn = st.button("ç”Ÿæˆåˆ†æç»“æœ", type="primary")
            
        except Exception as e:
            st.error(f"è¯»å–é”™è¯¯: {e}")

if uploaded_file and factors and targets and test_factor and run_btn:
    st.divider()
    with st.spinner("æ­£åœ¨ç”Ÿæˆå¤šæ ¼å¼æ•°æ®..."):
        try:
            res = run_comprehensive_analysis(df, factors, targets, test_factor)
            
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ğŸ“ˆ ç»„å†… (åˆ†åˆ—-ä½œå›¾)", 
                "ğŸ“‘ ç»„å†… (ç»„åˆ-åˆ¶è¡¨)", 
                "ğŸ† ä¸»æ•ˆåº” (å¤§å†™)", 
                "ğŸ§® ANOVA", 
                "ğŸ”— ç›¸å…³æ€§"
            ])
            
            with tab1:
                st.subheader(f"1. ç»„å†…æ¯”è¾ƒ - åˆ†åˆ—æ•°æ® (æŒ‰ {test_factor})")
                st.caption("é¡ºåºï¼šMean -> Letter -> SD | é€‚åˆå¯¼å…¥ Origin/GraphPad")
                if not res['sliced_table_sep'].empty:
                    st.dataframe(res['sliced_table_sep'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®")

            with tab2:
                st.subheader(f"2. ç»„å†…æ¯”è¾ƒ - ç»„åˆæ ‡ç­¾ (æŒ‰ {test_factor})")
                st.caption("ç»“æ„ï¼šMean_Letter | é€‚åˆç›´æ¥ç²˜è´´åˆ° Word è¡¨æ ¼")
                if not res['sliced_table_comb'].empty:
                    st.dataframe(res['sliced_table_comb'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®")

            with tab3:
                st.subheader("3. ä¸»æ•ˆåº”æ¯”è¾ƒ (Uppercase)")
                st.caption("ç»“æ„ï¼šMean_Letter Only (æ—  SD)")
                if not res['main_effects_table'].empty:
                    st.dataframe(res['main_effects_table'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®")

            with tab4:
                st.subheader("4. æ–¹å·®åˆ†æ (F-value)")
                if not res['anova_table'].empty:
                    st.dataframe(res['anova_table'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®")

            with tab5:
                st.subheader("5. ç›¸å…³æ€§çŸ©é˜µ")
                st.dataframe(res['correlation'], use_container_width=True)
            
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer) as writer:
                if not res['sliced_table_sep'].empty: 
                    res['sliced_table_sep'].to_excel(writer, sheet_name='ç»„å†…_åˆ†åˆ—æ•°æ®')
                if not res['sliced_table_comb'].empty: 
                    res['sliced_table_comb'].to_excel(writer, sheet_name='ç»„å†…_ç»„åˆæ ‡ç­¾')
                if not res['main_effects_table'].empty: 
                    res['main_effects_table'].to_excel(writer, sheet_name='ä¸»æ•ˆåº”_å¤§å†™')
                if not res['anova_table'].empty: 
                    res['anova_table'].to_excel(writer, sheet_name='ANOVA')
                if not res['correlation'].empty: 
                    res['correlation'].to_excel(writer, sheet_name='ç›¸å…³åˆ†æ')
                
            st.download_button(
                "ğŸ“¥ ä¸‹è½½å®Œæ•´æ•°æ®åŒ… (Excel)",
                data=buffer.getvalue(),
                file_name="Analysis_Formatted.xlsx",
                mime="application/vnd.ms-excel"
            )
            
        except Exception as e:
            st.error(f"åˆ†æå¤±è´¥: {e}")
            import traceback
            st.text(traceback.format_exc())





