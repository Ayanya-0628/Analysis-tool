import streamlit as st
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import pearsonr, t
import itertools
import io
import concurrent.futures
import os
import time

# ==========================================
# 0. UI ç¾åŒ–å·¥å…· (æ–°å¢éƒ¨åˆ†)
# ==========================================

def styled_tag(text, icon=""):
Â  Â  """
Â  Â  æ¸²æŸ“ä¸€ä¸ªèƒ¶å›Šå½¢çŠ¶çš„æ ‡é¢˜
Â  Â  """
Â  Â  st.markdown(f"""
Â  Â  <div style="
Â  Â  Â  Â  display: inline-flex;
Â  Â  Â  Â  align-items: center;
Â  Â  Â  Â  background-color: #e3f2fd; /* æ·¡è“è‰²èƒŒæ™¯ */
Â  Â  Â  Â  color: #1565c0; /* æ·±è“è‰²æ–‡å­— */
Â  Â  Â  Â  padding: 6px 16px;
Â  Â  Â  Â  border-radius: 20px; /* åœ†è§’èƒ¶å›Šå½¢çŠ¶ */
Â  Â  Â  Â  font-weight: 600;
Â  Â  Â  Â  font-size: 15px;
Â  Â  Â  Â  margin-bottom: 15px;
Â  Â  Â  Â  margin-top: 5px;
Â  Â  Â  Â  border: 1px solid #bbdefb;
Â  Â  Â  Â  box-shadow: 0 1px 2px rgba(0,0,0,0.05);
Â  Â  ">
Â  Â  Â  Â  <span style="margin-right: 8px; font-size: 18px;">{icon}</span>
Â  Â  Â  Â  {text}
Â  Â  </div>
Â  Â  """, unsafe_allow_html=True)

# ==========================================
# 1. æ ¸å¿ƒç»Ÿè®¡å·¥å…· (ä¿æŒä¸å˜)
# ==========================================

def get_stars(p_value):
Â  Â  if p_value < 0.001: return '***'
Â  Â  if p_value < 0.01:Â  return '**'
Â  Â  if p_value < 0.05:Â  return '*'
Â  Â  return 'ns'

def pairwise_lsd_test_with_mse(stats_df, mse, df_resid, alpha=0.05):
Â  Â  results = []
Â  Â  group_names = stats_df.index.tolist()
Â  Â  for g1, g2 in itertools.combinations(group_names, 2):
Â  Â  Â  Â  m1, n1 = stats_df.loc[g1, 'mean'], stats_df.loc[g1, 'count']
Â  Â  Â  Â  m2, n2 = stats_df.loc[g2, 'mean'], stats_df.loc[g2, 'count']
Â  Â  Â  Â  diff = m1 - m2
Â  Â  Â  Â  se = np.sqrt(mse * (1/n1 + 1/n2))
Â  Â  Â  Â  if se <= 1e-10:Â 
Â  Â  Â  Â  Â  Â  p_val = 1.0
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  t_stat = abs(diff) / se
Â  Â  Â  Â  Â  Â  p_val = 2 * (1 - t.cdf(t_stat, df_resid))
Â  Â  Â  Â  reject = p_val < alpha
Â  Â  Â  Â  results.append([g1, g2, diff, p_val, reject])
Â  Â  return results

def solve_clique_cld(means, pairwise_data, use_uppercase=False):
Â  Â  groups = [str(g).strip() for g in means.index.tolist()]
Â  Â  n = len(groups)
Â  Â  g_to_i = {g: i for i, g in enumerate(groups)}
Â  Â  adj = np.ones((n, n), dtype=bool)Â 
Â  Â  if pairwise_data:
Â  Â  Â  Â  for row in pairwise_data:
Â  Â  Â  Â  Â  Â  g1, g2, reject = str(row[0]).strip(), str(row[1]).strip(), row[4]
Â  Â  Â  Â  Â  Â  if reject:Â 
Â  Â  Â  Â  Â  Â  Â  Â  if g1 in g_to_i and g2 in g_to_i:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  i, j = g_to_i[g1], g_to_i[g2]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  adj[i, j] = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  adj[j, i] = False
Â  Â  np.fill_diagonal(adj, False)
Â  Â  cliques = []
Â  Â  def bron_kerbosch(R, P, X):
Â  Â  Â  Â  if len(P) == 0 and len(X) == 0:
Â  Â  Â  Â  Â  Â  cliques.append(R)
Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  union_px = P.union(X)
Â  Â  Â  Â  if not union_px: pivot = None
Â  Â  Â  Â  else: pivot = next(iter(union_px))
Â  Â  Â  Â  neighbors_pivot = {idx for idx in range(n) if adj[pivot, idx]} if pivot is not None else set()
Â  Â  Â  Â  for v in list(P - neighbors_pivot):
Â  Â  Â  Â  Â  Â  neighbors_v = {idx for idx in range(n) if adj[v, idx]}
Â  Â  Â  Â  Â  Â  bron_kerbosch(R.union({v}), P.intersection(neighbors_v), X.intersection(neighbors_v))
Â  Â  Â  Â  Â  Â  P.remove(v)
Â  Â  Â  Â  Â  Â  X.add(v)
Â  Â  bron_kerbosch(set(), set(range(n)), set())
Â  Â  clique_means = []
Â  Â  for clq in cliques:
Â  Â  Â  Â  avg_mean = np.mean([means.iloc[i] for i in clq])
Â  Â  Â  Â  clique_means.append((avg_mean, clq))
Â  Â  clique_means.sort(key=lambda x: x[0], reverse=True)
Â  Â Â 
Â  Â  letters_list = "ABCDEFGHIJKLMNOPQRSTUVWXYZ" if use_uppercase else "abcdefghijklmnopqrstuvwxyz"
Â  Â  group_letters = {i: "" for i in range(n)}
Â  Â  for idx, (avg, clq) in enumerate(clique_means):
Â  Â  Â  Â  char = letters_list[idx] if idx < len(letters_list) else "?"
Â  Â  Â  Â  for node_idx in clq:
Â  Â  Â  Â  Â  Â  group_letters[node_idx] += char
Â  Â  final_res = {}
Â  Â  original_index = means.index.tolist()
Â  Â  for i in range(n):
Â  Â  Â  Â  l_str = "".join(sorted(group_letters[i]))
Â  Â  Â  Â  final_res[str(original_index[i]).strip()] = l_str
Â  Â  return final_res

# ==========================================
# 2. å¹¶è¡ŒåŒ–æ ¸å¿ƒé€»è¾‘ (ä¿æŒä¸å˜)
# ==========================================

def process_single_target(target, df_data, factors, test_factor, mse_strategy):
Â  Â  res = {
Â  Â  Â  Â  'anova_rows': [],
Â  Â  Â  Â  'main_effects_rows': [],
Â  Â  Â  Â  'sliced_comparison_rows': [],
Â  Â  Â  Â  'error': None
Â  Â  }
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  current_df = df_data.dropna(subset=[target] + factors).copy()
Â  Â  Â  Â Â 
Â  Â  Â  Â  if current_df.empty or len(current_df) < 3:
Â  Â  Â  Â  Â  Â  return resÂ 

Â  Â  Â  Â  group_factors = [f for f in factors if f != test_factor]

Â  Â  Â  Â  factor_terms = [f'Q("{f}")' for f in factors]
Â  Â  Â  Â  formula_rhs = " * ".join(factor_terms)
Â  Â  Â  Â  formula = f"Q('{target}') ~ {formula_rhs}"
Â  Â  Â  Â Â 
Â  Â  Â  Â  model = ols(formula, data=current_df).fit()
Â  Â  Â  Â Â 
Â  Â  Â  Â  global_mse = model.mse_resid
Â  Â  Â  Â  global_df_resid = model.df_resid
Â  Â  Â  Â Â 
Â  Â  Â  Â  aov_table = sm.stats.anova_lm(model, typ=2)
Â  Â  Â  Â  aov_table.index = [idx.replace('Q("', '').replace('")', '') for idx in aov_table.index]

Â  Â  Â  Â  for source, row in aov_table.iterrows():
Â  Â  Â  Â  Â  Â  if source == 'Residual': continue
Â  Â  Â  Â  Â  Â  f_str = f"{row['F']:.2f}{get_stars(row['PR(>F)'])}"
Â  Â  Â  Â  Â  Â  res['anova_rows'].append({
Â  Â  Â  Â  Â  Â  Â  Â  'Trait': target,
Â  Â  Â  Â  Â  Â  Â  Â  'Source': source,
Â  Â  Â  Â  Â  Â  Â  Â  'F_Sig': f_str
Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â Â 
Â  Â  Â  Â  for factor in factors:
Â  Â  Â  Â  Â  Â  stats = current_df.groupby(factor)[target].agg(['mean', 'std', 'count']).fillna(0)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if mse_strategy == 'oneway':
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sub_formula = f"Q('{target}') ~ C(Q('{factor}'))"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sub_model = ols(sub_formula, data=current_df).fit()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_mse = sub_model.mse_resid
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_df_resid = sub_model.df_resid
Â  Â  Â  Â  Â  Â  Â  Â  except:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_mse = global_mse
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_df_resid = global_df_resid
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  current_mse = global_mse
Â  Â  Â  Â  Â  Â  Â  Â  current_df_resid = global_df_resid

Â  Â  Â  Â  Â  Â  if len(stats) < 2:
Â  Â  Â  Â  Â  Â  Â  Â  letters = {str(k).strip(): 'A' for k in stats.index}
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  pairwise_res = pairwise_lsd_test_with_mse(stats, current_mse, current_df_resid, alpha=0.05)
Â  Â  Â  Â  Â  Â  Â  Â  letters = solve_clique_cld(stats['mean'], pairwise_res, use_uppercase=True)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  for lvl in stats.index:
Â  Â  Â  Â  Â  Â  Â  Â  lvl_str = str(lvl).strip()
Â  Â  Â  Â  Â  Â  Â  Â  mean_val = stats.loc[lvl, 'mean']
Â  Â  Â  Â  Â  Â  Â  Â  res['main_effects_rows'].append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Factor': factor,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Level': lvl_str,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Trait': target,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Mean_Letter': f"{mean_val:.2f} {letters.get(lvl_str, 'A')}",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'SD': stats.loc[lvl, 'std']
Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  if not group_factors:
Â  Â  Â  Â  Â  Â  iter_groups = [( "All", current_df )]Â 
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  iter_groups = current_df.groupby(group_factors)

Â  Â  Â  Â  for group_keys, sub_df in iter_groups:
Â  Â  Â  Â  Â  Â  if not isinstance(group_keys, tuple): group_keys = (group_keys,)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  current_info = {'Trait': target}
Â  Â  Â  Â  Â  Â  if group_factors:
Â  Â  Â  Â  Â  Â  Â  Â  for k, val in zip(group_factors, group_keys):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_info[k] = str(val)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  stats = sub_df.groupby(test_factor)[target].agg(['mean', 'std', 'count']).fillna(0)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if len(stats) < 2:
Â  Â  Â  Â  Â  Â  Â  Â  letters = {str(k).strip(): 'a' for k in stats.index}
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  pairwise_res = pairwise_lsd_test_with_mse(stats, global_mse, global_df_resid, alpha=0.05)
Â  Â  Â  Â  Â  Â  Â  Â  letters = solve_clique_cld(stats['mean'], pairwise_res, use_uppercase=False)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  for lvl in stats.index:
Â  Â  Â  Â  Â  Â  Â  Â  lvl_str = str(lvl).strip()
Â  Â  Â  Â  Â  Â  Â  Â  mean_val = stats.loc[lvl, 'mean']
Â  Â  Â  Â  Â  Â  Â  Â  let = letters.get(lvl_str, 'a')
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  row = current_info.copy()
Â  Â  Â  Â  Â  Â  Â  Â  row[test_factor] = lvl_str
Â  Â  Â  Â  Â  Â  Â  Â  row['Mean'] = mean_val
Â  Â  Â  Â  Â  Â  Â  Â  row['SD'] = stats.loc[lvl, 'std']
Â  Â  Â  Â  Â  Â  Â  Â  row['Letter'] = let
Â  Â  Â  Â  Â  Â  Â  Â  row['Mean_Letter'] = f"{mean_val:.2f} {let}"
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  res['sliced_comparison_rows'].append(row)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  except Exception as e:
Â  Â  Â  Â  res['error'] = f"æŒ‡æ ‡ '{target}' å‡ºé”™: {str(e)}"
Â  Â Â 
Â  Â  return res

def run_parallel_analysis(df, factors, targets, test_factor, mse_strategy):
Â  Â  results = {}
Â  Â  errors = []
Â  Â Â 
Â  Â  work_df = df.copy()
Â  Â  for f in factors:
Â  Â  Â  Â  work_df[f] = work_df[f].astype(str).str.strip()
Â  Â Â 
Â  Â  valid_targets = []
Â  Â  for t_col in targets:
Â  Â  Â  Â  work_df[t_col] = pd.to_numeric(work_df[t_col], errors='coerce')
Â  Â  Â  Â  if not work_df[t_col].dropna().empty:
Â  Â  Â  Â  Â  Â  valid_targets.append(t_col)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  errors.append(f"æŒ‡æ ‡ '{t_col}' å…¨ä¸ºç©ºå€¼ï¼Œè·³è¿‡ã€‚")

Â  Â  all_anova = []
Â  Â  all_main = []
Â  Â  all_sliced = []

Â  Â  max_workers = os.cpu_count() or 4
Â  Â Â 
Â  Â  status_text = st.empty()
Â  Â  progress_bar = st.progress(0)
Â  Â Â 
Â  Â  status_text.write(f"ğŸš€ æ­£åœ¨å¯åŠ¨ {max_workers} ä¸ª CPU æ ¸å¿ƒè¿›è¡Œå¹¶è¡Œè®¡ç®—...")
Â  Â Â 
Â  Â  start_time = time.time()
Â  Â Â 
Â  Â  with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
Â  Â  Â  Â  future_to_target = {
Â  Â  Â  Â  Â  Â  executor.submit(process_single_target, t, work_df[[t] + factors], factors, test_factor, mse_strategy): tÂ 
Â  Â  Â  Â  Â  Â  for t in valid_targets
Â  Â  Â  Â  }
Â  Â  Â  Â Â 
Â  Â  Â  Â  completed_count = 0
Â  Â  Â  Â  total_tasks = len(valid_targets)
Â  Â  Â  Â Â 
Â  Â  Â  Â  for future in concurrent.futures.as_completed(future_to_target):
Â  Â  Â  Â  Â  Â  t_name = future_to_target[future]
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  data = future.result()
Â  Â  Â  Â  Â  Â  Â  Â  if data['error']:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  errors.append(data['error'])
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_anova.extend(data['anova_rows'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_main.extend(data['main_effects_rows'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_sliced.extend(data['sliced_comparison_rows'])
Â  Â  Â  Â  Â  Â  except Exception as exc:
Â  Â  Â  Â  Â  Â  Â  Â  errors.append(f"{t_name} è¿›ç¨‹å´©æºƒ: {exc}")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  completed_count += 1
Â  Â  Â  Â  Â  Â  if total_tasks > 0:
Â  Â  Â  Â  Â  Â  Â  Â  progress = completed_count / total_tasks
Â  Â  Â  Â  Â  Â  Â  Â  progress_bar.progress(progress)
Â  Â  Â  Â  Â  Â  status_text.write(f"æ­£åœ¨å¤„ç†: {completed_count}/{total_tasks} ({t_name})")

Â  Â  elapsed_time = time.time() - start_time
Â  Â  status_text.success(f"âœ… åˆ†æå®Œæˆï¼è€—æ—¶: {elapsed_time:.2f} ç§’")
Â  Â  time.sleep(1)
Â  Â  status_text.empty()
Â  Â  progress_bar.empty()

Â  Â  if all_anova:
Â  Â  Â  Â  results['anova_table'] = pd.DataFrame(all_anova).pivot_table(
Â  Â  Â  Â  Â  Â  index='Source', columns='Trait', values='F_Sig', aggfunc='first'
Â  Â  Â  Â  )
Â  Â  else:
Â  Â  Â  Â  results['anova_table'] = pd.DataFrame()

Â  Â  if all_main:
Â  Â  Â  Â  me_df = pd.DataFrame(all_main)
Â  Â  Â  Â  me_pivot = me_df.pivot_table(
Â  Â  Â  Â  Â  Â  index=['Factor', 'Level'], columns='Trait', values=['Mean_Letter'], aggfunc='first'
Â  Â  Â  Â  )
Â  Â  Â  Â  results['main_effects_table'] = me_pivot.swaplevel(0, 1, axis=1).sort_index(axis=1)
Â  Â  else:
Â  Â  Â  Â  results['main_effects_table'] = pd.DataFrame()

Â  Â  if all_sliced:
Â  Â  Â  Â  sc_df = pd.DataFrame(all_sliced)
Â  Â  Â  Â  group_factors = [f for f in factors if f != test_factor]
Â  Â  Â  Â  pivot_index = group_factors + [test_factor]
Â  Â  Â  Â Â 
Â  Â  Â  Â  sc_pivot_sep = sc_df.pivot_table(
Â  Â  Â  Â  Â  Â  index=pivot_index, columns='Trait', values=['Mean', 'Letter', 'SD'], aggfunc='first'
Â  Â  Â  Â  )
Â  Â  Â  Â  sc_pivot_sep = sc_pivot_sep.swaplevel(0, 1, axis=1).sort_index(axis=1, level=0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  sorted_traits = sc_pivot_sep.columns.get_level_values(0).unique()
Â  Â  Â  Â  new_columns = []
Â  Â  Â  Â  for t in sorted_traits:
Â  Â  Â  Â  Â  Â  for val in ['Mean', 'Letter', 'SD']:
Â  Â  Â  Â  Â  Â  Â  Â  if (t, val) in sc_pivot_sep.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_columns.append((t, val))
Â  Â  Â  Â  results['sliced_table_sep'] = sc_pivot_sep.reindex(columns=new_columns)
Â  Â  Â  Â Â 
Â  Â  Â  Â  sc_pivot_comb = sc_df.pivot_table(
Â  Â  Â  Â  Â  Â  index=pivot_index, columns='Trait', values=['Mean_Letter'], aggfunc='first'
Â  Â  Â  Â  )
Â  Â  Â  Â  results['sliced_table_comb'] = sc_pivot_comb.swaplevel(0, 1, axis=1).sort_index(axis=1)
Â  Â  else:
Â  Â  Â  Â  results['sliced_table_sep'] = pd.DataFrame()
Â  Â  Â  Â  results['sliced_table_comb'] = pd.DataFrame()

Â  Â  if len(valid_targets) > 1:
Â  Â  Â  Â  corr_df = work_df[valid_targets].corr()Â 
Â  Â  Â  Â  pval_df = work_df[valid_targets].corr(method=lambda x, y: pearsonr(x, y)[1])Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  corr_matrix = pd.DataFrame(index=valid_targets, columns=valid_targets)
Â  Â  Â  Â  for r_idx in valid_targets:
Â  Â  Â  Â  Â  Â  for c_idx in valid_targets:
Â  Â  Â  Â  Â  Â  Â  Â  if r_idx == c_idx:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  corr_matrix.loc[r_idx, c_idx] = "-"
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  r = corr_df.loc[r_idx, c_idx]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  p = pval_df.loc[r_idx, c_idx]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.isna(r):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  corr_matrix.loc[r_idx, c_idx] = "NaN"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  corr_matrix.loc[r_idx, c_idx] = f"{r:.2f}{get_stars(p)}"
Â  Â  Â  Â  results['correlation'] = corr_matrix
Â  Â  else:
Â  Â  Â  Â  results['correlation'] = pd.DataFrame()

Â  Â  results['errors'] = errors
Â  Â  return results

# ==========================================
# 3. Streamlit ç•Œé¢ (èƒ¶å›Šæ ·å¼ç‰ˆ)
# ==========================================

st.set_page_config(page_title="æ•°æ®åˆ†æ", layout="wide", page_icon="âš¡")
st.title("æ•°æ®åˆ†æ")

# ä¾§è¾¹æ 
with st.sidebar:
Â  Â  # ğŸŸ¢ ä½¿ç”¨ styled_tag æ›¿ä»£åŸæœ¬çš„ st.header("1. æ•°æ®ä¸Šä¼ ")
Â  Â  styled_tag("æ•°æ®ä¸Šä¼ ", icon="ğŸ“‚")
Â  Â Â 
Â  Â  uploaded_file = st.file_uploader("é€‰æ‹© Excel/CSV æ–‡ä»¶", type=['xlsx', 'csv'])
Â  Â Â 
Â  Â  # ğŸŸ¢ ä½¿ç”¨ styled_tag æ›¿ä»£ st.header("2. å› å­é€‰æ‹©")
Â  Â  styled_tag("å› å­é€‰æ‹©", icon="ğŸ§¬")
Â  Â Â 
Â  Â  factors = []
Â  Â  targets = []
Â  Â  test_factor = None
Â  Â  mse_strategy = 'oneway'Â 
Â  Â Â 
Â  Â  if uploaded_file:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  if uploaded_file.name.endswith('.csv'):
Â  Â  Â  Â  Â  Â  Â  Â  df = pd.read_csv(uploaded_file)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  excel_file = pd.ExcelFile(uploaded_file)
Â  Â  Â  Â  Â  Â  Â  Â  sheet_names = excel_file.sheet_names
Â  Â  Â  Â  Â  Â  Â  Â  if len(sheet_names) > 1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"ğŸ“‚ åŒ…å« {len(sheet_names)} ä¸ªSheet")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  selected_sheet = st.selectbox("é€‰æ‹©å·¥ä½œè¡¨:", sheet_names)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df = excel_file.parse(selected_sheet)
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df = excel_file.parse(0)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  df.columns = df.columns.astype(str)
Â  Â  Â  Â  Â  Â  all_cols = df.columns.tolist()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  Â  Â  factors = st.multiselect("å› å­ (X)", all_cols)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if factors:
Â  Â  Â  Â  Â  Â  Â  Â  default_idx = len(factors) - 1
Â  Â  Â  Â  Â  Â  Â  Â  test_factor = st.selectbox("æ¯”è¾ƒå› å­ (ç”¨äºç»„å†…æ¯”è¾ƒ)", factors, index=default_idx)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  targets = st.multiselect("æŒ‡æ ‡ (Y)", all_cols)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  Â  Â  with st.expander("âš™ï¸ æ¨¡å‹è®¾ç½® (é»˜è®¤å•å› ç´ )", expanded=False):
Â  Â  Â  Â  Â  Â  Â  Â  strategy_label = st.radio(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "è¯¯å·®è®¡ç®—æ–¹å¼",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ('å¤šå› ç´ æ¨¡å‹è¯¯å·®(GLM)', 'å•å› ç´ æ¨¡å‹è¯¯å·®'),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  index=1,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  help="å¤šå› ç´ ï¼šå‰¥ç¦»å…¶ä»–å› å­å¹²æ‰°ï¼ŒMSEå°ã€‚\nå•å› ç´ ï¼šå®Œå…¨åŸºäºåŸå§‹æ•°æ®æ³¢åŠ¨ï¼ŒMSEå¤§ã€‚"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  mse_strategy = 'full' if 'å¤šå› ç´ ' in strategy_label else 'oneway'
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  st.error(f"è¯»å–é”™è¯¯: {e}")

# ä¸»ç•Œé¢åŒºåŸŸ
with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜(ç‚¹å‡»å±•å¼€)", expanded=True):
Â  Â  col1, col2 = st.columns([0.45, 0.55])Â 
Â  Â  with col1:
Â  Â  Â  Â  st.markdown("### ğŸ“‹ æ•°æ®å‡†å¤‡ç¤ºä¾‹")
Â  Â  Â  Â  demo_data = pd.DataFrame({
Â  Â  Â  Â  Â  Â 'å“ç§': ['V1', 'V1', 'V1', 'V2'],
Â  Â  Â  Â  Â  Â  'å¤„ç†': ['CK', 'CK', 'CK', 'CK'],
Â  Â  Â  Â  Â  Â  'é‡å¤': ['R1', 'R2', 'R3', 'R1'],
Â  Â  Â  Â  Â  Â  'äº§é‡(kg)': [500.2, 520.5, 480.1, 600.5],
Â  Â  Â  Â  Â  Â  'æ ªé«˜(cm)': [100.5, 105.2, 98.4, 110.2]
Â  Â  Â  Â  })
Â  Â  Â  Â  st.dataframe(demo_data, hide_index=True, use_container_width=True)
Â  Â  with col2:
Â  Â  Â  Â  st.markdown("""
Â  Â  Â  Â  ### ğŸ› ï¸ æ“ä½œæç¤º
Â  Â  Â  Â  1. **å·¦ä¾§ä¸Šä¼ æ•°æ®**ï¼Œé€‰æ‹©å¯¹åº”çš„å› å­å’ŒæŒ‡æ ‡ã€‚
Â  Â  Â  Â  2. **ä¸‹æ–¹ç‚¹å‡»â€œå¯åŠ¨åˆ†æâ€**ã€‚
Â  Â  Â  Â  3. ç»“æœç”Ÿæˆåå¯ä¸‹è½½ Excelã€‚
Â  Â  Â  Â  """)

if uploaded_file and factors and targets and test_factor:
Â  Â  st.markdown("###")Â 
Â  Â Â 
Â  Â  c1, c2, c3 = st.columns([1, 2, 1])
Â  Â  with c2:
Â  Â  Â  Â  run_btn = st.button("ğŸš€ ç«‹å³å¯åŠ¨å¹¶è¡Œåˆ†æ", type="primary", use_container_width=True)

Â  Â  if run_btn:
Â  Â  Â  Â  st.divider()
Â  Â  Â  Â  res = run_parallel_analysis(df, factors, targets, test_factor, mse_strategy)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  if res.get('errors'):
Â  Â  Â  Â  Â  Â  with st.expander("âš ï¸ éƒ¨åˆ†æŒ‡æ ‡åˆ†æå¤±è´¥", expanded=False):
Â  Â  Â  Â  Â  Â  Â  Â  for err in res['errors']:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(err)
Â  Â  Â  Â Â 
Â  Â  Â  Â  tab1, tab2, tab3, tab4, tab5 = st.tabs([
Â  Â  Â  Â  Â  Â  "ğŸ“ˆ ç»„å†… (åˆ†åˆ—)",Â 
Â  Â  Â  Â  Â  Â  "ğŸ“‘ ç»„å†… (ç»„åˆ)",Â 
Â  Â  Â  Â  Â  Â  "ğŸ† ä¸»æ•ˆåº”",Â 
Â  Â  Â  Â  Â  Â  "ğŸ§® ANOVA",Â 
Â  Â  Â  Â  Â  Â  "ğŸ”— ç›¸å…³æ€§"
Â  Â  Â  Â  ])
Â  Â  Â  Â Â 
Â  Â  Â  Â  with tab1:
Â  Â  Â  Â  Â  Â  st.subheader(f"1. ç»„å†…æ¯”è¾ƒ - åˆ†åˆ—æ•°æ®")
Â  Â  Â  Â  Â  Â  if not res['sliced_table_sep'].empty:
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(res['sliced_table_sep'], width='stretch')
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("æ— æ•°æ®")

Â  Â  Â  Â  with tab2:
Â  Â  Â  Â  Â  Â  st.subheader(f"2. ç»„å†…æ¯”è¾ƒ - ç»„åˆæ ‡ç­¾")
Â  Â  Â  Â  Â  Â  if not res['sliced_table_comb'].empty:
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(res['sliced_table_comb'], width='stretch')
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("æ— æ•°æ®")

Â  Â  Â  Â  with tab3:
Â  Â  Â  Â  Â  Â  title_suffix = "(åŸºäºå•å› ç´ è¯¯å·®)" if mse_strategy == 'oneway' else "(åŸºäºå…¨æ¨¡å‹è¯¯å·®)"
Â  Â  Â  Â  Â  Â  st.subheader(f"3. ä¸»æ•ˆåº”æ¯”è¾ƒ {title_suffix}")
Â  Â  Â  Â  Â  Â  if not res['main_effects_table'].empty:
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(res['main_effects_table'], width='stretch')
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("æ— æ•°æ®")

Â  Â  Â  Â  with tab4:
Â  Â  Â  Â  Â  Â  st.subheader("4. æ–¹å·®åˆ†æ (F-value)")
Â  Â  Â  Â  Â  Â  if not res['anova_table'].empty:
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(res['anova_table'], width='stretch')
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("æ— æ•°æ®")

Â  Â  Â  Â  with tab5:
Â  Â  Â  Â  Â  Â  st.subheader("5. ç›¸å…³æ€§çŸ©é˜µ")
Â  Â  Â  Â  Â  Â  if not res['correlation'].empty:
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(res['correlation'], width='stretch')
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.info("æ•°æ®ä¸è¶³ä»¥è®¡ç®—ç›¸å…³æ€§")
Â  Â  Â  Â Â 
Â  Â  Â  Â  buffer = io.BytesIO()
Â  Â  Â  Â  with pd.ExcelWriter(buffer) as writer:
Â  Â  Â  Â  Â  Â  if not res['sliced_table_sep'].empty:Â 
Â  Â  Â  Â  Â  Â  Â  Â  res['sliced_table_sep'].to_excel(writer, sheet_name='ç»„å†…_åˆ†åˆ—æ•°æ®')
Â  Â  Â  Â  Â  Â  if not res['sliced_table_comb'].empty:Â 
Â  Â  Â  Â  Â  Â  Â  Â  res['sliced_table_comb'].to_excel(writer, sheet_name='ç»„å†…_ç»„åˆæ ‡ç­¾')
Â  Â  Â  Â  Â  Â  if not res['main_effects_table'].empty:Â 
Â  Â  Â  Â  Â  Â  Â  Â  res['main_effects_table'].to_excel(writer, sheet_name='ä¸»æ•ˆåº”_å¤§å†™')
Â  Â  Â  Â  Â  Â  if not res['anova_table'].empty:Â 
Â  Â  Â  Â  Â  Â  Â  Â  res['anova_table'].to_excel(writer, sheet_name='ANOVA')
Â  Â  Â  Â  Â  Â  if not res['correlation'].empty:Â 
Â  Â  Â  Â  Â  Â  Â  Â  res['correlation'].to_excel(writer, sheet_name='ç›¸å…³åˆ†æ')
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  "ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ (Excel)",
Â  Â  Â  Â  Â  Â  data=buffer.getvalue(),
Â  Â  Â  Â  Â  Â  file_name=f"Analysis_{mse_strategy}.xlsx",
Â  Â  Â  Â  Â  Â  mime="application/vnd.ms-excel"
Â  Â  Â  Â  )
elif uploaded_file:
Â  Â  st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ é€‰æ‹©ã€å› å­ã€‘å’Œã€æŒ‡æ ‡ã€‘ä»¥æ¿€æ´»åˆ†ææŒ‰é’®")
else:
Â  Â  st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ•°æ®æ–‡ä»¶")
