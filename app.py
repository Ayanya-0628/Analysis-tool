import streamlit as st
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import pearsonr, t
import itertools
import io

# ==========================================
# 1. æ ¸å¿ƒç»Ÿè®¡å·¥å…· (ä¿æŒä¸å˜)
# ==========================================

def get_stars(p_value):
    """å°†På€¼è½¬æ¢ä¸ºæ˜Ÿå·"""
    if p_value < 0.001: return '***'
    if p_value < 0.01:  return '**'
    if p_value < 0.05:  return '*'
    return 'ns'

def pairwise_lsd_test_with_mse(stats_df, mse, df_resid, alpha=0.05):
    """
    ä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„ MSE (æ¥è‡ªå…¨æ¨¡å‹) è¿›è¡Œ Fisher's LSD æ£€éªŒ
    """
    results = []
    group_names = stats_df.index.tolist()
    
    # ä¸¤ä¸¤æ¯”è¾ƒ
    for g1, g2 in itertools.combinations(group_names, 2):
        m1, n1 = stats_df.loc[g1]
        m2, n2 = stats_df.loc[g2]
        
        diff = m1 - m2
        # LSD æ ‡å‡†è¯¯
        se = np.sqrt(mse * (1/n1 + 1/n2))
        
        if se <= 1e-10: 
            p_val = 1.0
        else:
            t_stat = abs(diff) / se
            p_val = 2 * (1 - t.cdf(t_stat, df_resid))
        
        reject = p_val < alpha
        results.append([g1, g2, diff, p_val, reject])
        
    return results

def solve_clique_cld(means, pairwise_data):
    """
    æœ€å¤§å›¢ç®—æ³•ç”Ÿæˆå­—æ¯æ ‡è®°
    """
    groups = [str(g).strip() for g in means.index.tolist()]
    n = len(groups)
    g_to_i = {g: i for i, g in enumerate(groups)}
    
    # åˆå§‹åŒ–ï¼šé»˜è®¤å…¨è¿æ¥
    adj = np.ones((n, n), dtype=bool) 
    
    # æ ¹æ®æ˜¾è‘—æ€§æ–­å¼€è¿æ¥
    if pairwise_data:
        for row in pairwise_data:
            g1 = str(row[0]).strip()
            g2 = str(row[1]).strip()
            reject = row[4]
            if reject: 
                if g1 in g_to_i and g2 in g_to_i:
                    i, j = g_to_i[g1], g_to_i[g2]
                    adj[i, j] = False
                    adj[j, i] = False

    # ç§»é™¤è‡ªç¯ (å…³é”®ä¿®å¤)
    np.fill_diagonal(adj, False)

    # Bron-Kerbosch æœ€å¤§å›¢ç®—æ³•
    cliques = []
    def bron_kerbosch(R, P, X):
        if len(P) == 0 and len(X) == 0:
            cliques.append(R)
            return
        pivot = next(iter(P.union(X))) if P.union(X) else None
        neighbors_pivot = {idx for idx in range(n) if adj[pivot, idx]} if pivot is not None else set()
        for v in list(P - neighbors_pivot):
            neighbors_v = {idx for idx in range(n) if adj[v, idx]}
            bron_kerbosch(R.union({v}), P.intersection(neighbors_v), X.intersection(neighbors_v))
            P.remove(v)
            X.add(v)

    bron_kerbosch(set(), set(range(n)), set())
    
    # åˆ†é…å­—æ¯
    clique_means = []
    for clq in cliques:
        avg_mean = np.mean([means.iloc[i] for i in clq])
        clique_means.append((avg_mean, clq))
    
    clique_means.sort(key=lambda x: x[0], reverse=True)
    
    letters_list = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
    group_letters = {i: "" for i in range(n)}
    
    for idx, (avg, clq) in enumerate(clique_means):
        char = letters_list[idx] if idx < len(letters_list) else "?"
        for node_idx in clq:
            group_letters[node_idx] += char
            
    final_res = {}
    original_index = means.index.tolist()
    for i in range(n):
        l_str = "".join(sorted(group_letters[i]))
        key_str = str(original_index[i]).strip()
        final_res[key_str] = l_str
        
    return final_res

# ==========================================
# 2. æ ¸å¿ƒæµç¨‹ï¼šå…¨èƒ½åˆ†æ (ä¸»æ•ˆåº” + åˆ‡ç‰‡)
# ==========================================

def run_comprehensive_analysis(df, factors, targets, test_factor):
    results = {}
    
    # 0. æ•°æ®æ¸…æ´—
    work_df = df.copy()
    for f in factors:
        work_df[f] = work_df[f].astype(str).str.strip()
        
    # åˆ†ç»„å› å­ (ç”¨äºåˆ‡ç‰‡æ¯”è¾ƒçš„èƒŒæ™¯å› å­)
    group_factors = [f for f in factors if f != test_factor]
    
    # å®¹å™¨
    anova_rows = []
    main_effects_rows = []
    sliced_comparison_rows = []
    
    for target in targets:
        try:
            # --- A. å…¨æ¨¡å‹ ANOVA & å…¨å±€è¯¯å·® ---
            formula = f"{target} ~ {' * '.join(factors)}"
            model = ols(formula, data=work_df).fit()
            
            # è®°å½• ANOVA
            aov_table = sm.stats.anova_lm(model, typ=2)
            for source, row in aov_table.iterrows():
                if source == 'Residual': continue
                anova_rows.append({
                    'Trait': target,
                    'Source': source,
                    'Df': int(row['df']),
                    'F-value': row['F'],
                    'P-value': row['PR(>F)'],
                    'Signif': get_stars(row['PR(>F)'])
                })
            
            # è·å–å…¨å±€ Pooled MSE (ç”¨äºæ‰€æœ‰åç»­æ¯”è¾ƒï¼Œä¿è¯æ£€éªŒæ•ˆèƒ½ä¸€è‡´)
            global_mse = model.mse_resid
            global_df_resid = model.df_resid
            
            # --- B. ä¸»æ•ˆåº”æ¯”è¾ƒ (Main Effects) ---
            # éå†æ¯ä¸€ä¸ªå› å­ï¼Œè®¡ç®—æ•´ä½“å‡å€¼å·®å¼‚
            for factor in factors:
                # 1. è®¡ç®—è¯¥å› å­çš„è¾¹é™…å‡å€¼
                stats = work_df.groupby(factor)[target].agg(['mean', 'count'])
                
                # 2. LSD æ¯”è¾ƒ
                if len(stats) < 2:
                    letters = {str(k).strip(): 'a' for k in stats.index}
                else:
                    pairwise_res = pairwise_lsd_test_with_mse(stats, global_mse, global_df_resid, alpha=0.05)
                    letters = solve_clique_cld(stats['mean'], pairwise_res)
                
                # 3. è®°å½•
                for lvl in stats.index:
                    mean_val = stats.loc[lvl, 'mean']
                    lvl_str = str(lvl).strip()
                    let = letters.get(lvl_str, 'a')
                    
                    main_effects_rows.append({
                        'Factor': factor,
                        'Level': lvl_str,
                        'Trait': target,
                        'Mean': mean_val,
                        'Letter': let,
                        'Label': f"{mean_val:.2f} {let}"
                    })

            # --- C. ç»„å†…åˆ‡ç‰‡æ¯”è¾ƒ (Sliced Comparison) ---
            # é€»è¾‘ï¼šå›ºå®š group_factorsï¼Œæ¯”è¾ƒ test_factor
            
            # ç¡®å®šéå†çš„åˆ†ç»„
            if not group_factors:
                iter_groups = [( "All", work_df )] # å•å› ç´ æƒ…å†µ
            else:
                iter_groups = work_df.groupby(group_factors)

            for group_keys, sub_df in iter_groups:
                if not isinstance(group_keys, tuple): group_keys = (group_keys,)
                
                # åŸºç¡€ä¿¡æ¯
                current_info = {'Trait': target}
                if group_factors:
                    for k, val in zip(group_factors, group_keys):
                        current_info[k] = str(val)
                
                # è®¡ç®—å¾…æµ‹å› å­çš„å‡å€¼
                stats = sub_df.groupby(test_factor)[target].agg(['mean', 'count'])
                
                # æ¯”è¾ƒ
                if len(stats) < 2:
                    letters = {str(k).strip(): 'a' for k in stats.index}
                else:
                    pairwise_res = pairwise_lsd_test_with_mse(stats, global_mse, global_df_resid, alpha=0.05)
                    letters = solve_clique_cld(stats['mean'], pairwise_res)
                
                # è®°å½•
                for lvl in stats.index:
                    mean_val = stats.loc[lvl, 'mean']
                    lvl_str = str(lvl).strip()
                    let = letters.get(lvl_str, 'a')
                    
                    row = current_info.copy()
                    row[test_factor] = lvl_str
                    row['Mean'] = mean_val
                    row['Letter'] = let
                    row['Label'] = f"{mean_val:.2f} {let}"
                    sliced_comparison_rows.append(row)
                    
        except Exception as e:
            # print(f"Error in {target}: {e}")
            pass

    # --- D. æ•´ç†è¾“å‡º ---
    
    # 1. ANOVA
    results['anova'] = pd.DataFrame(anova_rows)
    
    # 2. ä¸»æ•ˆåº”
    if main_effects_rows:
        me_df = pd.DataFrame(main_effects_rows)
        results['main_effects'] = me_df
        # Pivot: Index=Factor+Level, Col=Trait
        results['main_effects_pivot'] = me_df.pivot_table(
            index=['Factor', 'Level'], columns='Trait', values='Label', aggfunc='first'
        ).reset_index()
    else:
        results['main_effects'] = pd.DataFrame()
        results['main_effects_pivot'] = pd.DataFrame()

    # 3. åˆ‡ç‰‡æ¯”è¾ƒ
    if sliced_comparison_rows:
        sliced_df = pd.DataFrame(sliced_comparison_rows)
        # æ•´ç†åˆ—é¡ºåº
        cols = group_factors + [test_factor, 'Trait', 'Mean', 'Letter', 'Label']
        final_cols = [c for c in cols if c in sliced_df.columns]
        results['sliced_comparison'] = sliced_df[final_cols]
        
        # Pivot
        pivot_index = group_factors + [test_factor]
        results['sliced_pivot'] = sliced_df.pivot_table(
            index=pivot_index, columns='Trait', values='Label', aggfunc='first'
        ).reset_index()
    else:
        results['sliced_comparison'] = pd.DataFrame()
        results['sliced_pivot'] = pd.DataFrame()
        
    # 4. ç›¸å…³æ€§
    if len(targets) > 1:
        corr_matrix = pd.DataFrame(index=targets, columns=targets)
        for t1 in targets:
            for t2 in targets:
                if t1 == t2:
                    corr_matrix.loc[t1, t2] = "-"
                else:
                    valid = df[[t1, t2]].dropna()
                    if len(valid) > 2:
                        r, p = pearsonr(valid[t1], valid[t2])
                        corr_matrix.loc[t1, t2] = f"{r:.2f}{get_stars(p)}"
                    else:
                        corr_matrix.loc[t1, t2] = "NaN"
        results['correlation'] = corr_matrix
    else:
        results['correlation'] = pd.DataFrame()

    return results

# ==========================================
# 3. Streamlit ç•Œé¢
# ==========================================

st.set_page_config(page_title="å†œä¸šç»Ÿè®¡å¹³å° (å…¨èƒ½ç‰ˆ)", layout="wide", page_icon="ğŸŒ¾")
st.title("ğŸŒ¾ ç®€å•çš„æ•°æ®åˆ†æ")
st.info("âœ… åŠŸèƒ½ï¼šæ–¹å·®åˆ†æ | ä¸»æ•ˆåº”å¤šé‡æ¯”è¾ƒ | ç»„å†…æ¯”è¾ƒ (å›ºå®šä¸»å› å­æ¯”è¾ƒå‰¯å› å­) | ç›¸å…³æ€§åˆ†æ")

with st.sidebar:
    st.header("1. æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader("ä¸Šä¼  Excel/CSV", type=['xlsx', 'csv'])
    
    st.header("2. å‚æ•°è®¾ç½®")
    factors = []
    targets = []
    test_factor = None
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            df.columns = df.columns.astype(str)
            all_cols = df.columns.tolist()
            
            st.markdown("---")
            st.write("ğŸ‘‰ **æ­¥éª¤ 1: é€‰æ‹©æ‰€æœ‰å‚ä¸å› å­çš„åˆ—**")
            factors = st.multiselect("å› å­ (X)", all_cols)
            
            if factors:
                st.markdown("ğŸ‘‰ **æ­¥éª¤ 2: é€‰æ‹©ç”¨äºç»„å†…æ¯”è¾ƒçš„å› å­**")
                st.caption("ä¾‹å¦‚ï¼šé€‰â€œå¤„ç†â€ï¼Œåˆ™åˆ†æä¼šå±•ç¤ºâ€œå“ç§Aä¸‹çš„å¤„ç†å·®å¼‚â€ã€â€œå“ç§Bä¸‹çš„å¤„ç†å·®å¼‚â€ã€‚")
                default_idx = len(factors) - 1
                test_factor = st.selectbox("æ¯”è¾ƒå› å­ (Test Factor)", factors, index=default_idx)
            
            st.markdown("ğŸ‘‰ **æ­¥éª¤ 3: é€‰æ‹©æŒ‡æ ‡**")
            targets = st.multiselect("æŒ‡æ ‡ (Y)", all_cols)
            
            run_btn = st.button("å¼€å§‹å…¨èƒ½åˆ†æ", type="primary")
            
        except Exception as e:
            st.error(f"è¯»å–é”™è¯¯: {e}")

if uploaded_file and factors and targets and test_factor and run_btn:
    st.divider()
    with st.spinner("æ­£åœ¨è¿›è¡Œå…¨æ–¹ä½åˆ†æ..."):
        try:
            res = run_comprehensive_analysis(df, factors, targets, test_factor)
            
            # ä½¿ç”¨ Tabs åˆ†å¼€å±•ç¤º
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ä¸»æ•ˆåº”æ¯”è¾ƒ", "ğŸ” ç»„å†…åˆ‡ç‰‡æ¯”è¾ƒ", "ğŸ“‘ æ–¹å·®åˆ†æ", "ğŸ”— ç›¸å…³æ€§"])
            
            with tab1:
                st.subheader("1. ä¸»æ•ˆåº”æ¯”è¾ƒ (Main Effects)")
                st.caption("å±•ç¤ºæ¯ä¸ªå› å­ï¼ˆå¦‚ä¸åŒå“ç§ã€ä¸åŒå¤„ç†ï¼‰çš„æ•´ä½“å‡å€¼å·®å¼‚ï¼Œå¿½ç•¥å…¶ä»–å› å­çš„å½±å“ã€‚")
                if not res['main_effects_pivot'].empty:
                    st.dataframe(res['main_effects_pivot'], use_container_width=True)
                    with st.expander("æŸ¥çœ‹è¯¦ç»†æ•°æ® (å« Mean å’Œ Letter ç‹¬ç«‹åˆ—)"):
                        st.dataframe(res['main_effects'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®ç”Ÿæˆ")

            with tab2:
                st.subheader(f"2. ç»„å†…åˆ‡ç‰‡æ¯”è¾ƒ (æŒ‰ {test_factor} è¿›è¡Œæ¯”è¾ƒ)")
                group_others = [f for f in factors if f != test_factor]
                st.caption(f"å±•ç¤ºåœ¨å›ºå®šèƒŒæ™¯ ({' + '.join(group_others) if group_others else 'æ— '}) ä¸‹ï¼Œ{test_factor} çš„å·®å¼‚ã€‚")
                
                if not res['sliced_pivot'].empty:
                    st.dataframe(res['sliced_pivot'], use_container_width=True)
                    with st.expander("æŸ¥çœ‹è¯¦ç»†æ•°æ® (å« Mean å’Œ Letter ç‹¬ç«‹åˆ—)"):
                        st.dataframe(res['sliced_comparison'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®ç”Ÿæˆ")
                
            with tab3:
                st.subheader("3. å…¨æ¨¡å‹æ–¹å·®åˆ†æè¡¨")
                st.dataframe(res['anova'], use_container_width=True)
                
            with tab4:
                st.subheader("4. ç›¸å…³æ€§åˆ†æ")
                st.dataframe(res['correlation'], use_container_width=True)
            
            # å¯¼å‡º
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer) as writer:
                # ä¸»æ•ˆåº”
                if not res['main_effects_pivot'].empty: 
                    res['main_effects_pivot'].to_excel(writer, sheet_name='ä¸»æ•ˆåº”_å®½è¡¨', index=False)
                if not res['main_effects'].empty: 
                    res['main_effects'].to_excel(writer, sheet_name='ä¸»æ•ˆåº”_æ˜ç»†', index=False)
                
                # åˆ‡ç‰‡æ¯”è¾ƒ
                if not res['sliced_pivot'].empty: 
                    res['sliced_pivot'].to_excel(writer, sheet_name='ç»„å†…åˆ‡ç‰‡_å®½è¡¨', index=False)
                if not res['sliced_comparison'].empty: 
                    res['sliced_comparison'].to_excel(writer, sheet_name='ç»„å†…åˆ‡ç‰‡_æ˜ç»†', index=False)
                
                # å…¶ä»–
                if not res['anova'].empty: 
                    res['anova'].to_excel(writer, sheet_name='ANOVA', index=False)
                if not res['correlation'].empty: 
                    res['correlation'].to_excel(writer, sheet_name='ç›¸å…³åˆ†æ')
                
            st.download_button(
                "ğŸ“¥ ä¸‹è½½å…¨èƒ½åˆ†ææŠ¥å‘Š (Excel)",
                data=buffer.getvalue(),
                file_name="Comprehensive_Analysis_Report.xlsx",
                mime="application/vnd.ms-excel"
            )
            
        except Exception as e:
            st.error(f"åˆ†æå¤±è´¥: {e}")
            import traceback

            st.text(traceback.format_exc())
