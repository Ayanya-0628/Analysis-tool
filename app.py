import streamlit as st
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import pearsonr, t
import itertools
import io

# ==========================================
# 1. æ ¸å¿ƒç»Ÿè®¡å·¥å…·
# ==========================================

def get_stars(p_value):
    """å°†På€¼è½¬æ¢ä¸ºæ˜Ÿå·"""
    if p_value < 0.001: return '***'
    if p_value < 0.01:  return '**'
    if p_value < 0.05:  return '*'
    return 'ns'

def pairwise_lsd_test_with_mse(stats_df, mse, df_resid, alpha=0.05):
    """Fisher's LSD æ£€éªŒ"""
    results = []
    group_names = stats_df.index.tolist()
    
    for g1, g2 in itertools.combinations(group_names, 2):
        m1, n1 = stats_df.loc[g1, 'mean'], stats_df.loc[g1, 'count']
        m2, n2 = stats_df.loc[g2, 'mean'], stats_df.loc[g2, 'count']
        
        diff = m1 - m2
        se = np.sqrt(mse * (1/n1 + 1/n2))
        
        if se <= 1e-10: 
            p_val = 1.0
        else:
            t_stat = abs(diff) / se
            p_val = 2 * (1 - t.cdf(t_stat, df_resid))
        
        reject = p_val < alpha
        results.append([g1, g2, diff, p_val, reject])
        
    return results

def solve_clique_cld(means, pairwise_data):
    """æœ€å¤§å›¢ç®—æ³•ç”Ÿæˆå­—æ¯æ ‡è®°"""
    groups = [str(g).strip() for g in means.index.tolist()]
    n = len(groups)
    g_to_i = {g: i for i, g in enumerate(groups)}
    adj = np.ones((n, n), dtype=bool) 
    
    if pairwise_data:
        for row in pairwise_data:
            g1, g2, reject = str(row[0]).strip(), str(row[1]).strip(), row[4]
            if reject: 
                if g1 in g_to_i and g2 in g_to_i:
                    i, j = g_to_i[g1], g_to_i[g2]
                    adj[i, j] = False
                    adj[j, i] = False

    np.fill_diagonal(adj, False) # ç§»é™¤è‡ªç¯

    cliques = []
    def bron_kerbosch(R, P, X):
        if len(P) == 0 and len(X) == 0:
            cliques.append(R)
            return
        pivot = next(iter(P.union(X))) if P.union(X) else None
        neighbors_pivot = {idx for idx in range(n) if adj[pivot, idx]} if pivot is not None else set()
        for v in list(P - neighbors_pivot):
            neighbors_v = {idx for idx in range(n) if adj[v, idx]}
            bron_kerbosch(R.union({v}), P.intersection(neighbors_v), X.intersection(neighbors_v))
            P.remove(v)
            X.add(v)

    bron_kerbosch(set(), set(range(n)), set())
    
    clique_means = []
    for clq in cliques:
        avg_mean = np.mean([means.iloc[i] for i in clq])
        clique_means.append((avg_mean, clq))
    
    clique_means.sort(key=lambda x: x[0], reverse=True)
    
    letters_list = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
    group_letters = {i: "" for i in range(n)}
    
    for idx, (avg, clq) in enumerate(clique_means):
        char = letters_list[idx] if idx < len(letters_list) else "?"
        for node_idx in clq:
            group_letters[node_idx] += char
            
    final_res = {}
    original_index = means.index.tolist()
    for i in range(n):
        l_str = "".join(sorted(group_letters[i]))
        final_res[str(original_index[i]).strip()] = l_str
        
    return final_res

# ==========================================
# 2. æ ¸å¿ƒæµç¨‹ï¼šç”Ÿæˆå¤šçº§è¡¨å¤´æ•°æ®
# ==========================================

def run_comprehensive_analysis(df, factors, targets, test_factor):
    results = {}
    
    # æ•°æ®æ¸…æ´—
    work_df = df.copy()
    for f in factors:
        work_df[f] = work_df[f].astype(str).str.strip()
        
    group_factors = [f for f in factors if f != test_factor]
    
    # å®¹å™¨
    anova_rows = []
    main_effects_rows = []
    sliced_comparison_rows = []
    
    for target in targets:
        try:
            # --- A. å…¨æ¨¡å‹ ANOVA ---
            formula = f"{target} ~ {' * '.join(factors)}"
            model = ols(formula, data=work_df).fit()
            
            aov_table = sm.stats.anova_lm(model, typ=2)
            global_mse = model.mse_resid
            global_df_resid = model.df_resid
            
            # è®°å½• ANOVA (Få€¼+æ˜Ÿå·)
            for source, row in aov_table.iterrows():
                if source == 'Residual': continue
                f_str = f"{row['F']:.2f}{get_stars(row['PR(>F)'])}"
                anova_rows.append({
                    'Trait': target,
                    'Source': source,
                    'F_Sig': f_str
                })
            
            # --- B. ä¸»æ•ˆåº” (åˆ†ç¦» Mean, SD, Letter) ---
            for factor in factors:
                stats = work_df.groupby(factor)[target].agg(['mean', 'std', 'count']).fillna(0)
                
                if len(stats) < 2:
                    letters = {str(k).strip(): 'a' for k in stats.index}
                else:
                    pairwise_res = pairwise_lsd_test_with_mse(stats, global_mse, global_df_resid, alpha=0.05)
                    letters = solve_clique_cld(stats['mean'], pairwise_res)
                
                for lvl in stats.index:
                    mean_val = stats.loc[lvl, 'mean']
                    sd_val = stats.loc[lvl, 'std']
                    lvl_str = str(lvl).strip()
                    let = letters.get(lvl_str, 'a')
                    
                    main_effects_rows.append({
                        'Factor': factor,
                        'Level': lvl_str,
                        'Trait': target,
                        'Mean': mean_val,
                        'SD': sd_val,
                        'Letter': let
                    })

            # --- C. åˆ‡ç‰‡æ¯”è¾ƒ (åˆ†ç¦» Mean, SD, Letter) ---
            if not group_factors:
                iter_groups = [( "All", work_df )] 
            else:
                iter_groups = work_df.groupby(group_factors)

            for group_keys, sub_df in iter_groups:
                if not isinstance(group_keys, tuple): group_keys = (group_keys,)
                
                current_info = {'Trait': target}
                if group_factors:
                    for k, val in zip(group_factors, group_keys):
                        current_info[k] = str(val)
                
                stats = sub_df.groupby(test_factor)[target].agg(['mean', 'std', 'count']).fillna(0)
                
                if len(stats) < 2:
                    letters = {str(k).strip(): 'a' for k in stats.index}
                else:
                    pairwise_res = pairwise_lsd_test_with_mse(stats, global_mse, global_df_resid, alpha=0.05)
                    letters = solve_clique_cld(stats['mean'], pairwise_res)
                
                for lvl in stats.index:
                    mean_val = stats.loc[lvl, 'mean']
                    sd_val = stats.loc[lvl, 'std']
                    lvl_str = str(lvl).strip()
                    let = letters.get(lvl_str, 'a')
                    
                    row = current_info.copy()
                    row[test_factor] = lvl_str
                    # ç‹¬ç«‹åˆ—
                    row['Mean'] = mean_val
                    row['SD'] = sd_val
                    row['Letter'] = let
                    sliced_comparison_rows.append(row)
                    
        except Exception as e:
            pass

    # --- D. æ„å»ºä¸‰çº¿è¡¨ (Multi-Index Pivot) ---
    
    # 1. ANOVA è¡¨ (Index=Source, Columns=Trait, Value=F_Sig)
    if anova_rows:
        anova_df = pd.DataFrame(anova_rows)
        results['anova_table'] = anova_df.pivot_table(
            index='Source', columns='Trait', values='F_Sig', aggfunc='first'
        )
    else:
        results['anova_table'] = pd.DataFrame()

    # 2. ä¸»æ•ˆåº”è¡¨ (Index=Factor+Level, Columns=Trait -> [Mean, SD, Letter])
    if main_effects_rows:
        me_df = pd.DataFrame(main_effects_rows)
        # æ ¸å¿ƒï¼šå¤šå€¼ Pivot
        me_pivot = me_df.pivot_table(
            index=['Factor', 'Level'], 
            columns='Trait', 
            values=['Mean', 'SD', 'Letter'], 
            aggfunc='first'
        )
        # è°ƒæ•´åˆ—é¡ºåºï¼šè®©æŒ‡æ ‡åœ¨æœ€ä¸Šå±‚ï¼ŒMean/SD/Letter åœ¨ä¸‹å±‚
        # swaplevel å°† (Mean, Yield) å˜æˆ (Yield, Mean)
        # sort_index è®©åŒä¸€ä¸ªæŒ‡æ ‡çš„ Mean/SD/Letter æŒ¨åœ¨ä¸€èµ·
        results['main_effects_table'] = me_pivot.swaplevel(0, 1, axis=1).sort_index(axis=1)
    else:
        results['main_effects_table'] = pd.DataFrame()

    # 3. åˆ‡ç‰‡æ¯”è¾ƒè¡¨ (Index=Group+TestFactor, Columns=Trait -> [Mean, SD, Letter])
    if sliced_comparison_rows:
        sc_df = pd.DataFrame(sliced_comparison_rows)
        pivot_index = group_factors + [test_factor]
        
        sc_pivot = sc_df.pivot_table(
            index=pivot_index, 
            columns='Trait', 
            values=['Mean', 'SD', 'Letter'], 
            aggfunc='first'
        )
        results['sliced_table'] = sc_pivot.swaplevel(0, 1, axis=1).sort_index(axis=1)
    else:
        results['sliced_table'] = pd.DataFrame()
        
    # 4. ç›¸å…³æ€§
    if len(targets) > 1:
        corr_matrix = pd.DataFrame(index=targets, columns=targets)
        for t1 in targets:
            for t2 in targets:
                if t1 == t2:
                    corr_matrix.loc[t1, t2] = "-"
                else:
                    valid = df[[t1, t2]].dropna()
                    if len(valid) > 2:
                        r, p = pearsonr(valid[t1], valid[t2])
                        corr_matrix.loc[t1, t2] = f"{r:.2f}{get_stars(p)}"
                    else:
                        corr_matrix.loc[t1, t2] = "NaN"
        results['correlation'] = corr_matrix
    else:
        results['correlation'] = pd.DataFrame()

    return results

# ==========================================
# 3. Streamlit ç•Œé¢
# ==========================================

st.set_page_config(page_title="è®ºæ–‡ä¸‰çº¿è¡¨ç”Ÿæˆå™¨ (åˆ†ç¦»ç‰ˆ)", layout="wide", page_icon="ğŸ“")
st.title("ğŸ“ è®ºæ–‡æ•°æ®ç”Ÿæˆå™¨ (Separated Mean/SD)")
st.info("âœ… å·²æ»¡è¶³ï¼šç»„å†…æ¯”è¾ƒã€ä¸»æ•ˆåº”å‡å·²å°† **Mean(å‡å€¼)**ã€**SD(æ ‡å‡†å·®)**ã€**Letter(å­—æ¯)** æ‹†åˆ†ä¸ºç‹¬ç«‹åˆ—ï¼Œä¸”æŒ‰æŒ‡æ ‡åˆ†ç»„æ’åˆ—ã€‚")

with st.sidebar:
    st.header("1. æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader("ä¸Šä¼  Excel/CSV", type=['xlsx', 'csv'])
    
    st.header("2. å‚æ•°è®¾ç½®")
    factors = []
    targets = []
    test_factor = None
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            df.columns = df.columns.astype(str)
            all_cols = df.columns.tolist()
            
            st.markdown("---")
            factors = st.multiselect("å› å­ (X)", all_cols)
            
            if factors:
                default_idx = len(factors) - 1
                test_factor = st.selectbox("æ¯”è¾ƒå› å­ (ç”¨äºç»„å†…æ¯”è¾ƒ)", factors, index=default_idx)
            
            targets = st.multiselect("æŒ‡æ ‡ (Y)", all_cols)
            
            run_btn = st.button("ç”Ÿæˆä¸‰çº¿è¡¨æ•°æ®", type="primary")
            
        except Exception as e:
            st.error(f"è¯»å–é”™è¯¯: {e}")

if uploaded_file and factors and targets and test_factor and run_btn:
    st.divider()
    with st.spinner("æ­£åœ¨æ„å»ºå¤šçº§è¡¨å¤´æ•°æ®..."):
        try:
            res = run_comprehensive_analysis(df, factors, targets, test_factor)
            
            # ä½¿ç”¨ Tabs å±•ç¤º
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ ç»„å†…æ¯”è¾ƒ (åˆ‡ç‰‡)", "ğŸ“ ä¸»æ•ˆåº”æ¯”è¾ƒ", "ğŸ“ æ–¹å·®åˆ†æ (Få€¼)", "ğŸ”— ç›¸å…³æ€§"])
            
            with tab1:
                st.subheader(f"Table 1. ç»„å†…å·®å¼‚ (æŒ‰ {test_factor})")
                st.caption("åˆ—ç»“æ„ï¼šæŒ‡æ ‡ -> [Letter, Mean, SD]")
                if not res['sliced_table'].empty:
                    st.dataframe(res['sliced_table'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®")

            with tab2:
                st.subheader("Table 2. ä¸»æ•ˆåº”å·®å¼‚")
                if not res['main_effects_table'].empty:
                    st.dataframe(res['main_effects_table'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®")

            with tab3:
                st.subheader("Table 3. æ–¹å·®åˆ†æç»“æœ")
                st.caption("F-value + Significance Stars")
                if not res['anova_table'].empty:
                    st.dataframe(res['anova_table'], use_container_width=True)
                else:
                    st.warning("æ— æ•°æ®")

            with tab4:
                st.subheader("Figure 1. ç›¸å…³æ€§çŸ©é˜µ")
                st.dataframe(res['correlation'], use_container_width=True)
            
            # å¯¼å‡ºé€»è¾‘
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer) as writer:
                # å†™å…¥æ‰€æœ‰ç”Ÿæˆçš„è¡¨æ ¼
                if not res['sliced_table'].empty: 
                    res['sliced_table'].to_excel(writer, sheet_name='Table_ç»„å†…æ¯”è¾ƒ')
                
                if not res['main_effects_table'].empty: 
                    res['main_effects_table'].to_excel(writer, sheet_name='Table_ä¸»æ•ˆåº”')
                
                if not res['anova_table'].empty: 
                    res['anova_table'].to_excel(writer, sheet_name='Table_æ–¹å·®åˆ†æ')
                
                if not res['correlation'].empty: 
                    res['correlation'].to_excel(writer, sheet_name='ç›¸å…³åˆ†æ')
                
            st.download_button(
                "ğŸ“¥ ä¸‹è½½ä¸‰çº¿è¡¨æ•°æ® (Excel)",
                data=buffer.getvalue(),
                file_name="Three_Line_Tables_Separated.xlsx",
                mime="application/vnd.ms-excel"
            )
            
        except Exception as e:
            st.error(f"åˆ†æå¤±è´¥: {e}")
            import traceback
            st.text(traceback.format_exc())
