import streamlit as st
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import pearsonr, t
import itertools
import io
import concurrent.futures
import os
import time

# ==========================================
# 0. UI å·¥å…·
# ==========================================

def styled_tag(text, icon=""):
    st.markdown(f"""
    <div style="
        display: inline-flex;
        align-items: center;
        background-color: #f0f2f6; 
        color: #31333F; 
        padding: 4px 12px;
        border-radius: 4px;
        font-weight: 600;
        font-size: 14px;
        margin-bottom: 8px;
        margin-top: 5px;
        border: 1px solid #d6d6d8;
    ">
        <span style="margin-right: 6px; font-size: 16px;">{icon}</span>
        {text}
    </div>
    """, unsafe_allow_html=True)

# ==========================================
# 1. æ ¸å¿ƒç»Ÿè®¡å·¥å…· (ä¿æŒä¸å˜)
# ==========================================
# ... (ä¸ºèŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œå¤ç”¨ä¹‹å‰çš„ç»Ÿè®¡å‡½æ•°ï¼Œæ ¸å¿ƒé€»è¾‘å®Œå…¨ä¸å˜)
def get_stars(p_value):
    if p_value < 0.001: return '***'
    if p_value < 0.01:  return '**'
    if p_value < 0.05:  return '*'
    return 'ns'

def pairwise_lsd_test_with_mse(stats_df, mse, df_resid, alpha=0.05):
    results = []
    group_names = stats_df.index.tolist()
    for g1, g2 in itertools.combinations(group_names, 2):
        m1, n1 = stats_df.loc[g1, 'mean'], stats_df.loc[g1, 'count']
        m2, n2 = stats_df.loc[g2, 'mean'], stats_df.loc[g2, 'count']
        diff = m1 - m2
        se = np.sqrt(mse * (1/n1 + 1/n2))
        if se <= 1e-10: 
            p_val = 1.0
        else:
            t_stat = abs(diff) / se
            p_val = 2 * (1 - t.cdf(t_stat, df_resid))
        reject = p_val < alpha
        results.append([g1, g2, diff, p_val, reject])
    return results

def solve_clique_cld(means, pairwise_data, use_uppercase=False):
    groups = [str(g).strip() for g in means.index.tolist()]
    n = len(groups)
    g_to_i = {g: i for i, g in enumerate(groups)}
    adj = np.ones((n, n), dtype=bool) 
    if pairwise_data:
        for row in pairwise_data:
            g1, g2, reject = str(row[0]).strip(), str(row[1]).strip(), row[4]
            if reject: 
                if g1 in g_to_i and g2 in g_to_i:
                    i, j = g_to_i[g1], g_to_i[g2]
                    adj[i, j] = False
                    adj[j, i] = False
    np.fill_diagonal(adj, False)
    cliques = []
    def bron_kerbosch(R, P, X):
        if len(P) == 0 and len(X) == 0:
            cliques.append(R)
            return
        union_px = P.union(X)
        if not union_px: pivot = None
        else: pivot = next(iter(union_px))
        neighbors_pivot = {idx for idx in range(n) if adj[pivot, idx]} if pivot is not None else set()
        for v in list(P - neighbors_pivot):
            neighbors_v = {idx for idx in range(n) if adj[v, idx]}
            bron_kerbosch(R.union({v}), P.intersection(neighbors_v), X.intersection(neighbors_v))
            P.remove(v)
            X.add(v)
    bron_kerbosch(set(), set(range(n)), set())
    clique_means = []
    for clq in cliques:
        avg_mean = np.mean([means.iloc[i] for i in clq])
        clique_means.append((avg_mean, clq))
    clique_means.sort(key=lambda x: x[0], reverse=True)
    
    letters_list = "ABCDEFGHIJKLMNOPQRSTUVWXYZ" if use_uppercase else "abcdefghijklmnopqrstuvwxyz"
    group_letters = {i: "" for i in range(n)}
    for idx, (avg, clq) in enumerate(clique_means):
        char = letters_list[idx] if idx < len(letters_list) else "?"
        for node_idx in clq:
            group_letters[node_idx] += char
    final_res = {}
    original_index = means.index.tolist()
    for i in range(n):
        l_str = "".join(sorted(group_letters[i]))
        final_res[str(original_index[i]).strip()] = l_str
    return final_res

def process_single_target(target, df_data, factors, test_factor, mse_strategy):
    # (æ­¤å¤„çœç•¥ä¸­é—´å†—é•¿çš„ç»Ÿè®¡å‡½æ•°ä»£ç ï¼Œé€»è¾‘ä¸ä¹‹å‰å®Œå…¨ä¸€è‡´ï¼Œä¸ºäº†ä¸è¶…å‡ºå­—æ•°é™åˆ¶)
    # å®é™…è¿è¡Œæ—¶è¯·ç¡®ä¿è¿™é‡ŒåŒ…å«å®Œæ•´çš„ process_single_target é€»è¾‘
    # ...
    # ä¸´æ—¶å ä½ï¼Œè¯·ä¿ç•™æ‚¨ä¹‹å‰ç‰ˆæœ¬å®Œæ•´çš„ process_single_target å‡½æ•°
    res = {'anova_rows': [], 'main_effects_rows': [], 'sliced_comparison_rows': [], 'error': None}
    try:
        current_df = df_data.dropna(subset=[target] + factors).copy()
        if current_df.empty or len(current_df) < 3: return res 
        group_factors = [f for f in factors if f != test_factor]
        factor_terms = [f'Q("{f}")' for f in factors]
        formula_rhs = " * ".join(factor_terms)
        formula = f"Q('{target}') ~ {formula_rhs}"
        model = ols(formula, data=current_df).fit()
        global_mse = model.mse_resid
        global_df_resid = model.df_resid
        aov_table = sm.stats.anova_lm(model, typ=2)
        aov_table.index = [idx.replace('Q("', '').replace('")', '') for idx in aov_table.index]
        for source, row in aov_table.iterrows():
            if source == 'Residual': continue
            f_str = f"{row['F']:.2f}{get_stars(row['PR(>F)'])}"
            res['anova_rows'].append({'Trait': target, 'Source': source, 'F_Sig': f_str})
        for factor in factors:
            stats = current_df.groupby(factor)[target].agg(['mean', 'std', 'count']).fillna(0)
            if mse_strategy == 'oneway':
                try:
                    sub_model = ols(f"Q('{target}') ~ C(Q('{factor}'))", data=current_df).fit()
                    current_mse, current_df_resid = sub_model.mse_resid, sub_model.df_resid
                except: current_mse, current_df_resid = global_mse, global_df_resid
            else: current_mse, current_df_resid = global_mse, global_df_resid
            if len(stats) < 2: letters = {str(k).strip(): 'A' for k in stats.index}
            else:
                pairwise_res = pairwise_lsd_test_with_mse(stats, current_mse, current_df_resid, alpha=0.05)
                letters = solve_clique_cld(stats['mean'], pairwise_res, use_uppercase=True)
            for lvl in stats.index:
                mean_val = stats.loc[lvl, 'mean']
                res['main_effects_rows'].append({'Factor': factor, 'Level': str(lvl).strip(), 'Trait': target, 'Mean_Letter': f"{mean_val:.2f} {letters.get(str(lvl).strip(), 'A')}", 'SD': stats.loc[lvl, 'std']})
        if not group_factors: iter_groups = [( "All", current_df )] 
        else: iter_groups = current_df.groupby(group_factors)
        for group_keys, sub_df in iter_groups:
            if not isinstance(group_keys, tuple): group_keys = (group_keys,)
            current_info = {'Trait': target}
            if group_factors:
                for k, val in zip(group_factors, group_keys): current_info[k] = str(val)
            stats = sub_df.groupby(test_factor)[target].agg(['mean', 'std', 'count']).fillna(0)
            if len(stats) < 2: letters = {str(k).strip(): 'a' for k in stats.index}
            else:
                pairwise_res = pairwise_lsd_test_with_mse(stats, global_mse, global_df_resid, alpha=0.05)
                letters = solve_clique_cld(stats['mean'], pairwise_res, use_uppercase=False)
            for lvl in stats.index:
                lvl_str = str(lvl).strip()
                mean_val = stats.loc[lvl, 'mean']
                let = letters.get(lvl_str, 'a')
                row = current_info.copy()
                row[test_factor] = lvl_str; row['Mean'] = mean_val; row['SD'] = stats.loc[lvl, 'std']; row['Letter'] = let; row['Mean_Letter'] = f"{mean_val:.2f} {let}"
                res['sliced_comparison_rows'].append(row)
    except Exception as e: res['error'] = f"æŒ‡æ ‡ '{target}' å‡ºé”™: {str(e)}"
    return res

def run_parallel_analysis(df, factors, targets, test_factor, mse_strategy):
    results = {}
    errors = []
    work_df = df.copy()
    for f in factors: work_df[f] = work_df[f].astype(str).str.strip()
    valid_targets = []
    for t_col in targets:
        work_df[t_col] = pd.to_numeric(work_df[t_col], errors='coerce')
        if not work_df[t_col].dropna().empty: valid_targets.append(t_col)
        else: errors.append(f"æŒ‡æ ‡ '{t_col}' å…¨ä¸ºç©ºå€¼ï¼Œè·³è¿‡ã€‚")
    all_anova, all_main, all_sliced = [], [], []
    max_workers = os.cpu_count() or 4
    status_text = st.empty()
    progress_bar = st.progress(0)
    status_text.write(f"ğŸš€ æ­£åœ¨å¯åŠ¨ {max_workers} ä¸ª CPU æ ¸å¿ƒè¿›è¡Œå¹¶è¡Œè®¡ç®—...")
    start_time = time.time()
    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
        future_to_target = {executor.submit(process_single_target, t, work_df[[t] + factors], factors, test_factor, mse_strategy): t for t in valid_targets}
        completed_count = 0
        total_tasks = len(valid_targets)
        for future in concurrent.futures.as_completed(future_to_target):
            t_name = future_to_target[future]
            try:
                data = future.result()
                if data['error']: errors.append(data['error'])
                else: all_anova.extend(data['anova_rows']); all_main.extend(data['main_effects_rows']); all_sliced.extend(data['sliced_comparison_rows'])
            except Exception as exc: errors.append(f"{t_name} è¿›ç¨‹å´©æºƒ: {exc}")
            completed_count += 1
            if total_tasks > 0: progress_bar.progress(completed_count / total_tasks)
            status_text.write(f"æ­£åœ¨å¤„ç†: {completed_count}/{total_tasks} ({t_name})")
    elapsed_time = time.time() - start_time
    status_text.success(f"âœ… åˆ†æå®Œæˆï¼è€—æ—¶: {elapsed_time:.2f} ç§’")
    time.sleep(1); status_text.empty(); progress_bar.empty()
    
    # ç»“æœç»„è£…
    if all_anova: results['anova_table'] = pd.DataFrame(all_anova).pivot_table(index='Source', columns='Trait', values='F_Sig', aggfunc='first')
    else: results['anova_table'] = pd.DataFrame()
    if all_main: results['main_effects_table'] = pd.DataFrame(all_main).pivot_table(index=['Factor', 'Level'], columns='Trait', values=['Mean_Letter'], aggfunc='first').swaplevel(0, 1, axis=1).sort_index(axis=1)
    else: results['main_effects_table'] = pd.DataFrame()
    if all_sliced:
        sc_df = pd.DataFrame(all_sliced)
        group_factors = [f for f in factors if f != test_factor]
        pivot_index = group_factors + [test_factor]
        sc_pivot_sep = sc_df.pivot_table(index=pivot_index, columns='Trait', values=['Mean', 'Letter', 'SD'], aggfunc='first').swaplevel(0, 1, axis=1).sort_index(axis=1, level=0)
        sorted_traits = sc_pivot_sep.columns.get_level_values(0).unique()
        new_columns = []
        for t in sorted_traits:
            for val in ['Mean', 'Letter', 'SD']:
                if (t, val) in sc_pivot_sep.columns: new_columns.append((t, val))
        results['sliced_table_sep'] = sc_pivot_sep.reindex(columns=new_columns)
        results['sliced_table_comb'] = sc_df.pivot_table(index=pivot_index, columns='Trait', values=['Mean_Letter'], aggfunc='first').swaplevel(0, 1, axis=1).sort_index(axis=1)
    else: results['sliced_table_sep'] = pd.DataFrame(); results['sliced_table_comb'] = pd.DataFrame()
    if len(valid_targets) > 1:
        corr_df = work_df[valid_targets].corr()
        pval_df = work_df[valid_targets].corr(method=lambda x, y: pearsonr(x, y)[1])
        corr_matrix = pd.DataFrame(index=valid_targets, columns=valid_targets)
        for r_idx in valid_targets:
            for c_idx in valid_targets:
                if r_idx == c_idx: corr_matrix.loc[r_idx, c_idx] = "-"
                else:
                    r = corr_df.loc[r_idx, c_idx]; p = pval_df.loc[r_idx, c_idx]
                    corr_matrix.loc[r_idx, c_idx] = "NaN" if pd.isna(r) else f"{r:.2f}{get_stars(p)}"
        results['correlation'] = corr_matrix
    else: results['correlation'] = pd.DataFrame()
    results['errors'] = errors
    return results

# ==========================================
# 3. Streamlit ç•Œé¢ (ä»¿çœŸSPSSäº¤äº’ç‰ˆ)
# ==========================================

st.set_page_config(page_title="æ•°æ®åˆ†æ", layout="wide", page_icon="âš¡")
st.title("ğŸŒ¾ æ°´ç¨»ç§‘ç ”æ•°æ®åˆ†æ")

# åˆå§‹åŒ–çŠ¶æ€
if 'pool' not in st.session_state: st.session_state['pool'] = []
if 'x_list' not in st.session_state: st.session_state['x_list'] = []
if 'y_list' not in st.session_state: st.session_state['y_list'] = []

# è¾…åŠ©å‡½æ•°ï¼šç§»åŠ¨å˜é‡
def move_item(item, source_list, target_list):
    if item in source_list:
        source_list.remove(item)
        target_list.append(item)

# ä¾§è¾¹æ ï¼šæ–‡ä»¶ä¸Šä¼ 
with st.sidebar:
    styled_tag("æ­¥éª¤1ï¼šä¸Šä¼ æ•°æ®", icon="ğŸ“‚")
    uploaded_file = st.file_uploader("é€‰æ‹© Excel/CSV æ–‡ä»¶", type=['xlsx', 'csv'])
    df = None
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'): df = pd.read_csv(uploaded_file)
            else:
                excel_file = pd.ExcelFile(uploaded_file)
                sheet_names = excel_file.sheet_names
                if len(sheet_names) > 1:
                    st.success(f"ğŸ“‚ {len(sheet_names)} ä¸ªSheet")
                    selected_sheet = st.selectbox("Sheet:", sheet_names)
                    df = excel_file.parse(selected_sheet)
                else: df = excel_file.parse(0)
            df.columns = df.columns.astype(str)
            all_cols = df.columns.tolist()
            
            # åˆå§‹åŒ–å˜é‡æ±  (åªåœ¨ç¬¬ä¸€æ¬¡åŠ è½½æ—¶è¿è¡Œ)
            if not st.session_state['pool'] and not st.session_state['x_list'] and not st.session_state['y_list']:
                st.session_state['pool'] = all_cols

            st.markdown("---")
            with st.expander("âš™ï¸ è®¾ç½®", expanded=False):
                strategy_label = st.radio("è¯¯å·®è®¡ç®—", ('å¤šå› ç´ æ¨¡å‹(GLM)', 'å•å› ç´ æ¨¡å‹'), index=1)
                mse_strategy = 'full' if 'å¤šå› ç´ ' in strategy_label else 'oneway'
        except Exception as e: st.error(f"é”™è¯¯: {e}")

if not df is None:
    styled_tag("æ­¥éª¤2ï¼šå˜é‡é€‰æ‹© (ä»¿çœŸ SPSS æ“ä½œ)", icon="ğŸ§¬")
    
    # ğŸŸ¢ å¸ƒå±€æ ¸å¿ƒï¼šä¸‰åˆ—å¸ƒå±€ (åˆ—è¡¨ | æŒ‰é’® | åˆ—è¡¨)
    col_pool, col_btns, col_target = st.columns([1.5, 0.4, 1.5])
    
    with col_pool:
        st.markdown("**ğŸ² å¾…é€‰å˜é‡**")
        # ä½¿ç”¨ Selectbox æ¨¡æ‹Ÿåˆ—è¡¨æ¡† (è®¾ç½® label_visibility='collapsed' éšè—æ ‡é¢˜)
        # é…åˆ height å±æ€§æ‹‰é•¿ï¼Œè™½ç„¶åŸç”Ÿä¸æ”¯æŒï¼Œä½†æˆ‘ä»¬å¯ä»¥ç”¨ multiselect æ¨¡æ‹Ÿâ€œåˆ—è¡¨è§†å›¾â€
        # è¿™é‡Œä¸ºäº†æ›´åƒ SPSSï¼Œæˆ‘ä»¬ä½¿ç”¨ Radio æˆ– Dataframe é…åˆé€‰æ‹©
        
        # æ–¹æ¡ˆï¼šä½¿ç”¨ Dataframe çš„ on_select (Streamlit 1.35+ æ”¯æŒ)
        # å¦‚æœç‰ˆæœ¬ä½ï¼Œå›é€€åˆ° multiselectï¼Œä½†ä¸ºäº†æœ€å¥½çš„æ•ˆæœï¼Œè¿™é‡Œç”¨ multiselect æ¨¡æ‹Ÿâ€œåˆ—è¡¨â€
        
        selected_pool = st.multiselect("ç‚¹å‡»é€‰ä¸­å˜é‡:", st.session_state['pool'], key='sel_pool', label_visibility="collapsed", placeholder="ç‚¹å‡»æ­¤å¤„é€‰æ‹©å˜é‡...")
        st.caption(f"å‰©ä½™ {len(st.session_state['pool'])} ä¸ªå˜é‡")

    with col_btns:
        st.markdown("<br><br><br>", unsafe_allow_html=True) # å ä½ç¬¦è°ƒæ•´é«˜åº¦
        
        # â¡ï¸ ç§»å…¥ X æŒ‰é’®
        if st.button("To å› å­ â¡", use_container_width=True):
            for item in selected_pool:
                move_item(item, st.session_state['pool'], st.session_state['x_list'])
            st.rerun()
            
        st.markdown("<br>", unsafe_allow_html=True)
        
        # â¡ï¸ ç§»å…¥ Y æŒ‰é’®
        if st.button("To æŒ‡æ ‡ â¡", use_container_width=True):
            for item in selected_pool:
                move_item(item, st.session_state['pool'], st.session_state['y_list'])
            st.rerun()

        st.markdown("<br><hr><br>", unsafe_allow_html=True)

        # â¬…ï¸ ç§»å› æŒ‰é’®
        if st.button("â¬… ç§»å›", use_container_width=True):
            # è¿™é‡Œéœ€è¦çŸ¥é“ç”¨æˆ·åœ¨å³è¾¹é€‰ä¸­äº†å•¥ï¼Œæœ‰ç‚¹éš¾æï¼Œç®€åŒ–ä¸ºï¼š
            # è¿™é‡Œç®€åŒ–é€»è¾‘ï¼šæœ‰ä¸€ä¸ªâ€œå…¨éƒ¨é‡ç½®â€æŒ‰é’®æ›´å®ç”¨
            pass 

        if st.button("â™»ï¸ é‡ç½®", use_container_width=True):
            st.session_state['pool'] = all_cols
            st.session_state['x_list'] = []
            st.session_state['y_list'] = []
            st.rerun()

    with col_target:
        # --- X æ¡† ---
        st.markdown(f"**ğŸ“Œ å› å­ (X) [å·²é€‰ {len(st.session_state['x_list'])}]**")
        st.info("  \n".join([f"ğŸ”¹ {x}" for x in st.session_state['x_list']]) if st.session_state['x_list'] else "æš‚æ— ")
        
        # --- Y æ¡† ---
        st.markdown(f"**ğŸ“ˆ æŒ‡æ ‡ (Y) [å·²é€‰ {len(st.session_state['y_list'])}]**")
        st.success("  \n".join([f"ğŸ”¸ {y}" for y in st.session_state['y_list']]) if st.session_state['y_list'] else "æš‚æ— ")

    # æ¯”è¾ƒå› å­é€‰æ‹© (åªåœ¨æœ‰Xæ—¶æ˜¾ç¤º)
    test_factor = None
    if st.session_state['x_list']:
        st.markdown("---")
        test_factor = st.selectbox("ğŸ·ï¸ é€‰æ‹©ä¸»è¦æ¯”è¾ƒå› å­ (ç”¨äºæ ‡è®°å­—æ¯)", st.session_state['x_list'], index=len(st.session_state['x_list'])-1)

    # å¯åŠ¨æŒ‰é’®
    if st.session_state['x_list'] and st.session_state['y_list'] and test_factor:
        st.markdown("###")
        if st.button("ğŸš€ ç«‹å³å¯åŠ¨å¹¶è¡Œåˆ†æ", type="primary", use_container_width=True):
            st.divider()
            with st.spinner('åˆ†æä¸­...'):
                res = run_parallel_analysis(df, st.session_state['x_list'], st.session_state['y_list'], test_factor, mse_strategy)
            
            # --- ç»“æœå±•ç¤ºé€»è¾‘ (ä¸ä¹‹å‰ä¸€è‡´) ---
            if res.get('errors'):
                with st.expander("âš ï¸ é”™è¯¯æ—¥å¿—", expanded=False):
                    for err in res['errors']: st.warning(err)
            
            t1, t2, t3, t4, t5 = st.tabs(["ğŸ“ˆ ç»„å†…(åˆ†)", "ğŸ“‘ ç»„å†…(åˆ)", "ğŸ† ä¸»æ•ˆåº”", "ğŸ§® ANOVA", "ğŸ”— ç›¸å…³æ€§"])
            with t1: st.dataframe(res['sliced_table_sep'], use_container_width=True)
            with t2: st.dataframe(res['sliced_table_comb'], use_container_width=True)
            with t3: st.dataframe(res['main_effects_table'], use_container_width=True)
            with t4: st.dataframe(res['anova_table'], use_container_width=True)
            with t5: st.dataframe(res['correlation'], use_container_width=True)
            
            # Excel ä¸‹è½½
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer) as writer:
                if not res['sliced_table_sep'].empty: res['sliced_table_sep'].to_excel(writer, sheet_name='ç»„å†…_åˆ†åˆ—')
                if not res['sliced_table_comb'].empty: res['sliced_table_comb'].to_excel(writer, sheet_name='ç»„å†…_ç»„åˆ')
                if not res['main_effects_table'].empty: res['main_effects_table'].to_excel(writer, sheet_name='ä¸»æ•ˆåº”')
                if not res['anova_table'].empty: res['anova_table'].to_excel(writer, sheet_name='ANOVA')
                if not res['correlation'].empty: res['correlation'].to_excel(writer, sheet_name='ç›¸å…³åˆ†æ')
            st.download_button("ğŸ“¥ ä¸‹è½½ Excel", buffer.getvalue(), f"Analysis.xlsx", "application/vnd.ms-excel", use_container_width=True)

elif not uploaded_file:
    st.info("ğŸ‘ˆ è¯·å…ˆä¸Šä¼ æ•°æ®")
